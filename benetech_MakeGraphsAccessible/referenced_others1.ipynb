{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5e9cc10",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-21T14:55:58.486773Z",
     "iopub.status.busy": "2023-06-21T14:55:58.485987Z",
     "iopub.status.idle": "2023-06-21T14:56:32.733969Z",
     "shell.execute_reply": "2023-06-21T14:56:32.732649Z"
    },
    "papermill": {
     "duration": 34.267,
     "end_time": "2023-06-21T14:56:32.736886",
     "exception": false,
     "start_time": "2023-06-21T14:55:58.469886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "aiobotocore 2.5.0 requires botocore<1.29.77,>=1.29.76, but you have botocore 1.29.157 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r /kaggle/input/github-benetech-dd/requirements.txt --no-index --find-links=file:///kaggle/input/benetech-sub-pip2 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09721765",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:56:32.769420Z",
     "iopub.status.busy": "2023-06-21T14:56:32.768210Z",
     "iopub.status.idle": "2023-06-21T14:56:45.793123Z",
     "shell.execute_reply": "2023-06-21T14:56:45.791846Z"
    },
    "papermill": {
     "duration": 13.043916,
     "end_time": "2023-06-21T14:56:45.795772",
     "exception": false,
     "start_time": "2023-06-21T14:56:32.751856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers  --no-index --find-links=file:///kaggle/input/benetech-sub-pip -q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7930195",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:56:45.828367Z",
     "iopub.status.busy": "2023-06-21T14:56:45.827173Z",
     "iopub.status.idle": "2023-06-21T14:56:46.927283Z",
     "shell.execute_reply": "2023-06-21T14:56:46.925846Z"
    },
    "papermill": {
     "duration": 1.119096,
     "end_time": "2023-06-21T14:56:46.929976",
     "exception": false,
     "start_time": "2023-06-21T14:56:45.810880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/github-benetech-dd/* ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a96bfcf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:56:46.961280Z",
     "iopub.status.busy": "2023-06-21T14:56:46.960895Z",
     "iopub.status.idle": "2023-06-21T14:56:54.351379Z",
     "shell.execute_reply": "2023-06-21T14:56:54.350285Z"
    },
    "papermill": {
     "duration": 7.409381,
     "end_time": "2023-06-21T14:56:54.353886",
     "exception": false,
     "start_time": "2023-06-21T14:56:46.944505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import importlib\n",
    "import multiprocessing as mp\n",
    "import gc\n",
    "from tqdm.auto import tqdm\n",
    "import glob\n",
    "import torch\n",
    "from copy import copy\n",
    "#from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import DataLoader\n",
    "import timm\n",
    "from PIL import Image\n",
    "import transformers\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17942b16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:56:54.387750Z",
     "iopub.status.busy": "2023-06-21T14:56:54.387079Z",
     "iopub.status.idle": "2023-06-21T14:56:54.393470Z",
     "shell.execute_reply": "2023-06-21T14:56:54.392389Z"
    },
    "papermill": {
     "duration": 0.025699,
     "end_time": "2023-06-21T14:56:54.395878",
     "exception": false,
     "start_time": "2023-06-21T14:56:54.370179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "sys.path.append('./configs')\n",
    "sys.path.append('./data')\n",
    "sys.path.append('./models')\n",
    "sys.path.append('./postprocess')\n",
    "sys.path.append('./scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4a0f253",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:56:54.428085Z",
     "iopub.status.busy": "2023-06-21T14:56:54.427710Z",
     "iopub.status.idle": "2023-06-21T14:56:56.067876Z",
     "shell.execute_reply": "2023-06-21T14:56:56.066793Z"
    },
    "papermill": {
     "duration": 1.659098,
     "end_time": "2023-06-21T14:56:56.070636",
     "exception": false,
     "start_time": "2023-06-21T14:56:54.411538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/153839247.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_files = pd.Series(glob.glob(f'{COMP_FOLDER}/test/images/*.*g')).str.replace('.jpg', '').str.split('/').str[-1]\n",
      "/tmp/ipykernel_24/153839247.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_files = pd.Series(glob.glob(f'{COMP_FOLDER}/train/images/*.*g')).str.replace('.jpg', '').str.split('/').str[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60578, 5)\n",
      "(5, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMP_FOLDER = '/kaggle/input/benetech-making-graphs-accessible/'\n",
    "DATA_FOLDER = COMP_FOLDER + 'test/'\n",
    "META_DF = COMP_FOLDER + 'test.csv'\n",
    "#train_df = pd.read_csv(COMP_FOLDER + 'train.csv')\n",
    "#test_df = pd.read_csv(COMP_FOLDER + 'test.csv')\n",
    "sample_submission = pd.read_csv(COMP_FOLDER + 'sample_submission.csv')\n",
    "test_files = pd.Series(glob.glob(f'{COMP_FOLDER}/test/images/*.*g')).str.replace('.jpg', '').str.split('/').str[-1]\n",
    "train_files = pd.Series(glob.glob(f'{COMP_FOLDER}/train/images/*.*g')).str.replace('.jpg', '').str.split('/').str[-1]\n",
    "test_df = pd.DataFrame({'id':test_files,'chart_type':'scatter','source_type':'extracted','flattened_label':'Jan;Feb;Mar||line||34.1;31.7;31.3||line'})\n",
    "test_df['fold'] = -1\n",
    "train_df = pd.DataFrame({'id':train_files,'chart_type':'scatter','source_type':'extracted','flattened_label':'Jan;Feb;Mar||line||34.1;31.7;31.3||line'})\n",
    "train_df['fold'] = -1\n",
    "PUBLIC_RUN = len(test_df) == 5\n",
    "N_CORES = mp.cpu_count()\n",
    "MIXED_PRECISION = False\n",
    "PIN_MEMORY = False\n",
    "\n",
    "RAM_CHECK = False\n",
    "OOF_CHECK = False\n",
    "FOLD = 0\n",
    "MAX_FOLDS = 99\n",
    "DL_PREFETCH_FACTOR = 2\n",
    "\n",
    "assert (RAM_CHECK + OOF_CHECK) <= 1\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "if PUBLIC_RUN is False:\n",
    "    RAM_CHECK = False\n",
    "    OOF_CHECK = False\n",
    "    \n",
    "if RAM_CHECK is True:\n",
    "    pass\n",
    "    \n",
    "if OOF_CHECK is True:\n",
    "    pass\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b60f00aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:56:56.104531Z",
     "iopub.status.busy": "2023-06-21T14:56:56.104081Z",
     "iopub.status.idle": "2023-06-21T14:56:56.120551Z",
     "shell.execute_reply": "2023-06-21T14:56:56.119381Z"
    },
    "papermill": {
     "duration": 0.036418,
     "end_time": "2023-06-21T14:56:56.123281",
     "exception": false,
     "start_time": "2023-06-21T14:56:56.086863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>chart_type</th>\n",
       "      <th>source_type</th>\n",
       "      <th>flattened_label</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000b92c3b098</td>\n",
       "      <td>scatter</td>\n",
       "      <td>extracted</td>\n",
       "      <td>Jan;Feb;Mar||line||34.1;31.7;31.3||line</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01b45b831589</td>\n",
       "      <td>scatter</td>\n",
       "      <td>extracted</td>\n",
       "      <td>Jan;Feb;Mar||line||34.1;31.7;31.3||line</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00f5404753cf</td>\n",
       "      <td>scatter</td>\n",
       "      <td>extracted</td>\n",
       "      <td>Jan;Feb;Mar||line||34.1;31.7;31.3||line</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00dcf883a459</td>\n",
       "      <td>scatter</td>\n",
       "      <td>extracted</td>\n",
       "      <td>Jan;Feb;Mar||line||34.1;31.7;31.3||line</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>007a18eb4e09</td>\n",
       "      <td>scatter</td>\n",
       "      <td>extracted</td>\n",
       "      <td>Jan;Feb;Mar||line||34.1;31.7;31.3||line</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id chart_type source_type  \\\n",
       "0  000b92c3b098    scatter   extracted   \n",
       "1  01b45b831589    scatter   extracted   \n",
       "2  00f5404753cf    scatter   extracted   \n",
       "3  00dcf883a459    scatter   extracted   \n",
       "4  007a18eb4e09    scatter   extracted   \n",
       "\n",
       "                           flattened_label  fold  \n",
       "0  Jan;Feb;Mar||line||34.1;31.7;31.3||line    -1  \n",
       "1  Jan;Feb;Mar||line||34.1;31.7;31.3||line    -1  \n",
       "2  Jan;Feb;Mar||line||34.1;31.7;31.3||line    -1  \n",
       "3  Jan;Feb;Mar||line||34.1;31.7;31.3||line    -1  \n",
       "4  Jan;Feb;Mar||line||34.1;31.7;31.3||line    -1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b11400c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:56:56.161716Z",
     "iopub.status.busy": "2023-06-21T14:56:56.161196Z",
     "iopub.status.idle": "2023-06-21T14:56:56.178371Z",
     "shell.execute_reply": "2023-06-21T14:56:56.177309Z"
    },
    "papermill": {
     "duration": 0.040259,
     "end_time": "2023-06-21T14:56:56.181365",
     "exception": false,
     "start_time": "2023-06-21T14:56:56.141106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cfg(CFG):\n",
    "    cfg = importlib.import_module('default_config')\n",
    "    importlib.reload(cfg)\n",
    "    cfg = importlib.import_module(CFG)\n",
    "    importlib.reload(cfg)\n",
    "    cfg = copy(cfg.cfg)\n",
    "    cfg.post_process_pipeline = None #importlib.import_module(cfg.post_process_pipeline).post_process_pipeline\n",
    "\n",
    "    cfg.data_dir = COMP_FOLDER\n",
    "    cfg.data_folder = DATA_FOLDER\n",
    "    cfg.test_data_folder = DATA_FOLDER\n",
    "    cfg.mixed_precision = MIXED_PRECISION\n",
    "    cfg.pretrained = False\n",
    "    cfg.pretrained_weights = False\n",
    "    cfg.batch_size = cfg.batch_size\n",
    "    cfg.offline_inference = True\n",
    "\n",
    "    print(CFG, cfg.model, cfg.dataset, cfg.backbone, cfg.pretrained_weights, cfg.post_process_pipeline)\n",
    "    \n",
    "    return cfg\n",
    "\n",
    "def get_dl(test_df, cfg):\n",
    "    ds = importlib.import_module(cfg.dataset)\n",
    "    importlib.reload(ds)\n",
    "\n",
    "    CustomDataset = ds.CustomDataset\n",
    "    batch_to_device = ds.batch_to_device\n",
    "\n",
    "    test_ds = CustomDataset(test_df, cfg, cfg.val_aug, mode=\"test\")\n",
    "    test_dl = DataLoader(test_ds, shuffle=False, batch_size=cfg.batch_size, collate_fn=ds.val_collate_fn, num_workers=N_CORES, pin_memory=PIN_MEMORY, prefetch_factor = DL_PREFETCH_FACTOR)\n",
    "\n",
    "    return test_dl, batch_to_device\n",
    "\n",
    "def get_state_dict(sd_fp):\n",
    "    sd = torch.load(sd_fp, map_location=\"cpu\")\n",
    "    if \"model\" in sd.keys():\n",
    "        sd = sd[\"model\"]\n",
    "    sd = {k.replace(\"module.\", \"\"):v for k,v in sd.items()}\n",
    "    return sd\n",
    "\n",
    "def get_nets(cfg,state_dicts):\n",
    "    model = importlib.import_module(cfg.model)\n",
    "    importlib.reload(model)\n",
    "    Net = model.Net\n",
    "\n",
    "    nets = []\n",
    "\n",
    "    for i,state_dict in enumerate(state_dicts):\n",
    "        net = Net(cfg).eval().to(DEVICE)\n",
    "        print(\"loading dict\")\n",
    "        sd = get_state_dict(state_dict)\n",
    "        net.load_state_dict(sd, strict=cfg.pretrained_weights_strict)\n",
    "        #nets += [net.half()]\n",
    "        nets += [net]\n",
    "        del sd\n",
    "        gc.collect()\n",
    "    return nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "960bcb9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:56:56.215362Z",
     "iopub.status.busy": "2023-06-21T14:56:56.214925Z",
     "iopub.status.idle": "2023-06-21T14:57:04.410675Z",
     "shell.execute_reply": "2023-06-21T14:57:04.409625Z"
    },
    "papermill": {
     "duration": 8.215751,
     "end_time": "2023-06-21T14:57:04.413230",
     "exception": false,
     "start_time": "2023-06-21T14:56:56.197479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/kaggle/input/benetech-cfg-ch-ct-1c-ff/fold-1/checkpoint_last_seed309705.pth', '/kaggle/input/benetech-cfg-ch-ct-1c-ff/fold-1/checkpoint_last_seed729826.pth', '/kaggle/input/benetech-cfg-ch-ct-1c-ff/fold-1/checkpoint_last_seed789023.pth']\n",
      "cfg_ch_ct_1c mdl_ch_4 ds_ch_4 tf_efficientnet_b0_ns False None\n",
      "scatter    5\n",
      "Name: chart_type, dtype: int64\n",
      "loading dict\n",
      "loading dict\n",
      "loading dict\n"
     ]
    }
   ],
   "source": [
    "CFG = 'cfg_ch_ct_1c'\n",
    "state_dicts = sorted(glob.glob('/kaggle/input/benetech-cfg-ch-ct-1c-ff/*/*.pth'))\n",
    "print(state_dicts)\n",
    "\n",
    "cfg = get_cfg(CFG)\n",
    "# cfg.batch_size = 2\n",
    "test_dl, batch_to_device = get_dl(test_df, cfg)\n",
    "nets = get_nets(cfg,state_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a8631ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:57:04.445421Z",
     "iopub.status.busy": "2023-06-21T14:57:04.444993Z",
     "iopub.status.idle": "2023-06-21T14:57:10.416282Z",
     "shell.execute_reply": "2023-06-21T14:57:10.414691Z"
    },
    "papermill": {
     "duration": 5.990884,
     "end_time": "2023-06-21T14:57:10.419628",
     "exception": false,
     "start_time": "2023-06-21T14:57:04.428744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8191b3ecae744e9a977dd6333ac5f667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "\n",
    "    preds = []\n",
    "    for batch in tqdm(test_dl):\n",
    "        batch = batch_to_device(batch, 'cuda')\n",
    "        batch_preds = []\n",
    "        for i, net in enumerate(nets):\n",
    "            logits = net(batch)['logits'].float().detach().cpu().numpy()\n",
    "            batch_preds += [logits]\n",
    "        preds += [np.stack(batch_preds, axis=1)]\n",
    "    preds = np.concatenate(preds)\n",
    "    preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e81194af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:57:10.454737Z",
     "iopub.status.busy": "2023-06-21T14:57:10.453432Z",
     "iopub.status.idle": "2023-06-21T14:57:10.461054Z",
     "shell.execute_reply": "2023-06-21T14:57:10.459893Z"
    },
    "papermill": {
     "duration": 0.028758,
     "end_time": "2023-06-21T14:57:10.463750",
     "exception": false,
     "start_time": "2023-06-21T14:57:10.434992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = preds.mean(1).argmax(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17975540",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:57:10.501092Z",
     "iopub.status.busy": "2023-06-21T14:57:10.499993Z",
     "iopub.status.idle": "2023-06-21T14:57:10.506077Z",
     "shell.execute_reply": "2023-06-21T14:57:10.504879Z"
    },
    "papermill": {
     "duration": 0.027101,
     "end_time": "2023-06-21T14:57:10.508729",
     "exception": false,
     "start_time": "2023-06-21T14:57:10.481628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chart_type_pred = np.array(cfg.chart_map)[preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "924fdc7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:57:10.543873Z",
     "iopub.status.busy": "2023-06-21T14:57:10.542734Z",
     "iopub.status.idle": "2023-06-21T14:57:10.550748Z",
     "shell.execute_reply": "2023-06-21T14:57:10.549690Z"
    },
    "papermill": {
     "duration": 0.028037,
     "end_time": "2023-06-21T14:57:10.553072",
     "exception": false,
     "start_time": "2023-06-21T14:57:10.525035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df['chart_type_pred'] = chart_type_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "561918a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:57:10.587272Z",
     "iopub.status.busy": "2023-06-21T14:57:10.586178Z",
     "iopub.status.idle": "2023-06-21T14:57:10.596839Z",
     "shell.execute_reply": "2023-06-21T14:57:10.595834Z"
    },
    "papermill": {
     "duration": 0.030212,
     "end_time": "2023-06-21T14:57:10.599280",
     "exception": false,
     "start_time": "2023-06-21T14:57:10.569068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_df['chart_type'] == test_df['chart_type_pred']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e017ab10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:57:10.633092Z",
     "iopub.status.busy": "2023-06-21T14:57:10.632177Z",
     "iopub.status.idle": "2023-06-21T14:57:16.043165Z",
     "shell.execute_reply": "2023-06-21T14:57:16.033864Z"
    },
    "papermill": {
     "duration": 5.437028,
     "end_time": "2023-06-21T14:57:16.051897",
     "exception": false,
     "start_time": "2023-06-21T14:57:10.614869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "    reader_close()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n"
     ]
    }
   ],
   "source": [
    "del nets, preds, test_dl\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c1272b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:57:16.100200Z",
     "iopub.status.busy": "2023-06-21T14:57:16.099797Z",
     "iopub.status.idle": "2023-06-21T14:57:16.105505Z",
     "shell.execute_reply": "2023-06-21T14:57:16.104344Z"
    },
    "papermill": {
     "duration": 0.026589,
     "end_time": "2023-06-21T14:57:16.107833",
     "exception": false,
     "start_time": "2023-06-21T14:57:16.081244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_chart_types = test_df['chart_type_pred'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f30702a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:57:16.142819Z",
     "iopub.status.busy": "2023-06-21T14:57:16.141761Z",
     "iopub.status.idle": "2023-06-21T14:57:16.155542Z",
     "shell.execute_reply": "2023-06-21T14:57:16.154406Z"
    },
    "papermill": {
     "duration": 0.034716,
     "end_time": "2023-06-21T14:57:16.158489",
     "exception": false,
     "start_time": "2023-06-21T14:57:16.123773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['line', 'vertical_bar', 'scatter'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_chart_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3619c7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:57:16.194544Z",
     "iopub.status.busy": "2023-06-21T14:57:16.193971Z",
     "iopub.status.idle": "2023-06-21T14:57:16.199009Z",
     "shell.execute_reply": "2023-06-21T14:57:16.197955Z"
    },
    "papermill": {
     "duration": 0.025121,
     "end_time": "2023-06-21T14:57:16.201626",
     "exception": false,
     "start_time": "2023-06-21T14:57:16.176505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06b870a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:57:16.237408Z",
     "iopub.status.busy": "2023-06-21T14:57:16.236405Z",
     "iopub.status.idle": "2023-06-21T14:57:24.490088Z",
     "shell.execute_reply": "2023-06-21T14:57:24.487684Z"
    },
    "papermill": {
     "duration": 8.275503,
     "end_time": "2023-06-21T14:57:24.493003",
     "exception": false,
     "start_time": "2023-06-21T14:57:16.217500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Dict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import timm\n",
    "from torch.distributions import Beta\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pad_sequence\n",
    "from transformers import DetrConfig, DetrForObjectDetection#, DetrHungarianMatcher\n",
    "from transformers.models.detr.modeling_detr import DetrHungarianMatcher, generalized_box_iou, center_to_corners_format\n",
    "import torch\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from transformers import DetrImageProcessor\n",
    "from transformers.models.detr.image_processing_detr import center_to_corners_format\n",
    "import imagesize\n",
    "from transformers import Pix2StructForConditionalGeneration, Pix2StructProcessor, AutoTokenizer, Pix2StructConfig\n",
    "from transformers import Pix2StructVisionModel, T5ForConditionalGeneration\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def gem(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1.0 / p)\n",
    "\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6, p_trainable=False):\n",
    "        super(GeM, self).__init__()\n",
    "        if p_trainable:\n",
    "            self.p = Parameter(torch.ones(1) * p)\n",
    "        else:\n",
    "            self.p = p\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        ret = gem(x, p=self.p, eps=self.eps)\n",
    "        return ret\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (self.__class__.__name__  + f\"(p={self.p.data.tolist()[0]:.4f},eps={self.eps})\")\n",
    "\n",
    "\n",
    "'''\n",
    "self = Net(cfg)\n",
    "'''\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg: Any):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        config = Pix2StructConfig()\n",
    "        config.vision_config.use_bfloat16 = cfg.use_bfloat16\n",
    "        config.text_config.use_bfloat16 = cfg.use_bfloat16\n",
    "        self.backbone = Pix2StructForConditionalGeneration.from_pretrained(cfg.backbone, config = config)\n",
    "        \n",
    "        self.processor = Pix2StructProcessor.from_pretrained(cfg.backbone, is_vqa = False)\n",
    "        sep_pos = self.processor.tokenizer.encode('\\;', add_special_tokens = False)\n",
    "        # wt1 = self.backbone.decoder.embed_tokens.weight[sep_pos]\n",
    "        wt0 = self.backbone.decoder.embed_tokens.weight#[:-2]\n",
    "        emb_wt = torch.cat((wt0, wt0[sep_pos]))\n",
    "        self.backbone.resize_token_embeddings(2+self.backbone.config.text_config.vocab_size)\n",
    "        self.loss_weights = torch.ones(self.backbone.config.text_config.vocab_size)\n",
    "        self.loss_weights[-2:] *= self.cfg.break_wt\n",
    "        self.backbone.decoder.embed_tokens.load_state_dict({'weight': emb_wt})\n",
    "        \n",
    "        # self.processor = Pix2StructProcessor.from_pretrained(cfg.backbone)\n",
    "        self.in_features = self.backbone.config.vision_config.hidden_size\n",
    "        self.chart_classifier = torch.nn.Linear(in_features=self.in_features, out_features=len(self.cfg.chart_map ), bias=True)\n",
    "        # self.dtype_classifier = torch.nn.Linear(in_features=self.in_features, out_features=len(self.cfg.dtype_map ), bias=True)\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "        calc_grad = False\n",
    "        for nm, param in self.backbone.named_parameters():\n",
    "            if cfg.freeze_from in nm:\n",
    "                calc_grad = True\n",
    "            param.requires_grad = calc_grad\n",
    "        # for nm, param in self.backbone.named_parameters():\n",
    "        #     print(param.requires_grad, nm)\n",
    "        self.loss_weights = torch.nn.Parameter(self.loss_weights, requires_grad=False)\n",
    "        # self.cfg.break_wt = 2.\n",
    "        \n",
    "        self.criterion_table = nn.CrossEntropyLoss(weight = self.loss_weights , ignore_index=-100, reduction=\"mean\")\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \n",
    "        labels = batch['series_label_1'].permute(1,0)\n",
    "        encoding = {k:v[:,0] for k,v in batch.items() if k in ['flattened_patches', 'attention_mask']}\n",
    "        predictions = self.backbone.generate(**encoding, \n",
    "                                                max_new_tokens=self.cfg.max_label_length, \n",
    "                                                early_stopping=True,\n",
    "                                                pad_token_id=self.processor.tokenizer.pad_token_id,\n",
    "                                                eos_token_id=self.processor.tokenizer.eos_token_id,\n",
    "                                                use_cache=True,\n",
    "                                                num_beams=self.cfg.num_beams,\n",
    "                                                temperature=self.cfg.temperature,\n",
    "                                                top_k=self.cfg.top_k,\n",
    "                                                return_dict_in_generate=True,\n",
    "                                                output_hidden_states = True)\n",
    "        logits_chart = self.chart_classifier(predictions.encoder_hidden_states[-1][:,0])\n",
    "        logits_table = predictions.sequences #[:,1:]\n",
    "        # print(logits_table)\n",
    "        loss = self.criterion(logits_chart, batch['chart_label'])\n",
    "\n",
    "        outputs = {}\n",
    "        outputs[\"loss\"] = loss\n",
    "        if not self.training:\n",
    "            # Calculate the required padding\n",
    "            padding = (0, self.cfg.max_label_length - logits_table.size(1))\n",
    "            # Pad the array along the 3rd dimension\n",
    "            logits_table  = F.pad(logits_table, padding, mode=\"constant\", value=0)\n",
    "            outputs[\"logits_table\"] = logits_table\n",
    "            outputs[\"logits_chart\"] = logits_chart\n",
    " \n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "baf1bcf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:57:24.528860Z",
     "iopub.status.busy": "2023-06-21T14:57:24.527705Z",
     "iopub.status.idle": "2023-06-21T14:57:24.536698Z",
     "shell.execute_reply": "2023-06-21T14:57:24.535545Z"
    },
    "papermill": {
     "duration": 0.029722,
     "end_time": "2023-06-21T14:57:24.539188",
     "exception": false,
     "start_time": "2023-06-21T14:57:24.509466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_state_dict(sd_fp):\n",
    "    sd = torch.load(sd_fp, map_location=\"cpu\")\n",
    "    if \"model\" in sd.keys():\n",
    "        sd = sd[\"model\"]\n",
    "    sd = {k.replace(\"module.\", \"\"):v for k,v in sd.items()}\n",
    "    return sd\n",
    "\n",
    "def get_nets(cfg,state_dicts):\n",
    "    model = importlib.import_module(cfg.model)\n",
    "    importlib.reload(model)\n",
    "    Net = model.Net\n",
    "\n",
    "    nets = []\n",
    "\n",
    "    for i,state_dict in enumerate(state_dicts):\n",
    "        net = Net(cfg).eval().to(DEVICE)\n",
    "        print(\"loading dict\")\n",
    "        sd = get_state_dict(state_dict)\n",
    "        net.load_state_dict(sd, strict=cfg.pretrained_weights_strict)\n",
    "        #nets += [net.half()]\n",
    "        nets += [net]\n",
    "        del sd\n",
    "        gc.collect()\n",
    "    return nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "847dfe15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:57:24.574351Z",
     "iopub.status.busy": "2023-06-21T14:57:24.573872Z",
     "iopub.status.idle": "2023-06-21T14:57:24.615197Z",
     "shell.execute_reply": "2023-06-21T14:57:24.614199Z"
    },
    "papermill": {
     "duration": 0.061823,
     "end_time": "2023-06-21T14:57:24.617435",
     "exception": false,
     "start_time": "2023-06-21T14:57:24.555612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch\n",
    "from transformers import LogitsProcessorList\n",
    "from transformers.generation.utils import GreedySearchOutput, GreedySearchEncoderDecoderOutput, GreedySearchDecoderOnlyOutput\n",
    "from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "import warnings\n",
    "from transformers import Pix2StructForConditionalGeneration, Pix2StructProcessor, AutoTokenizer\n",
    "from transformers import StoppingCriteriaList,  MaxLengthCriteria\n",
    "\n",
    "\n",
    "        \n",
    "'''\n",
    "Reference code:\n",
    "https://github.com/huggingface/transformers/blob/118e9810687dd713b6be07af79e80eeb1d916908/src/transformers/generation/utils.py#L2164\n",
    "'''\n",
    "       \n",
    "\n",
    "\n",
    "class Pix2StructGreedySearch(Pix2StructForConditionalGeneration):\n",
    "    def __init__(self, \n",
    "                 models, \n",
    "                 max_length = 512):\n",
    "        super().__init__(models[0].config)\n",
    "        \n",
    "        del self.encoder \n",
    "        del self.decoder \n",
    "        self.models = models\n",
    "        self.is_vqa  = False\n",
    "        self.logits_processor = LogitsProcessorList([])\n",
    "        self.stopping_criteria = StoppingCriteriaList([MaxLengthCriteria(max_length=max_length)])\n",
    "        \n",
    "        '''\n",
    "        Reference code:\n",
    "        https://github.com/huggingface/transformers/blob/118e9810687dd713b6be07af79e80eeb1d916908/src/transformers/generation/utils.py#L2164\n",
    "        '''\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        flattened_patches: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        use_cache = True,\n",
    "        return_dict_in_generate = False,\n",
    "        output_hidden_states = False,\n",
    "        \n",
    "        ):\n",
    "\n",
    "        if self.models[0].device != flattened_patches.device:\n",
    "            self.models = [m.to(flattened_patches.device) for m in self.models]\n",
    "        #print(self.models[0].device)\n",
    "        #print(flattened_patches.device)\n",
    "\n",
    "        encoder_outputs_list  = [m.encoder(flattened_patches = flattened_patches, \n",
    "                                           attention_mask = attention_mask) for m in self.models]\n",
    "        input_ids = torch.tensor([[self.models[0].config.pad_token_id]] * len(flattened_patches), \n",
    "                                 device = flattened_patches.device) # '<pad>' token to begin\n",
    "        # attention_mask = attention_mask\n",
    "        # print(flattened_patches.shape)\n",
    "        # print(input_ids.shape)\n",
    "        \n",
    "        output = self.greedy_search(encoder_outputs_list, \n",
    "                                               attention_mask, \n",
    "                                               input_ids, \n",
    "                                               output_attentions = False,\n",
    "                                               output_hidden_states = output_hidden_states,\n",
    "                                               output_scores = False,\n",
    "                                               return_dict_in_generate =return_dict_in_generate\n",
    "                                    \n",
    "                                                \n",
    "                                   \n",
    "                                   )\n",
    "                \n",
    "        return output\n",
    "\n",
    "    def greedy_search(\n",
    "        self,\n",
    "        encoder_outputs_list,\n",
    "        attention_mask,\n",
    "        input_ids: torch.LongTensor,\n",
    "        stopping_criteria: Optional[StoppingCriteriaList] = None,\n",
    "        # max_length: Optional[int] = None,\n",
    "        pad_token_id: Optional[int] = None,\n",
    "        eos_token_id: Optional[Union[int, List[int]]] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        output_scores: Optional[bool] = None,\n",
    "        return_dict_in_generate: Optional[bool] = None,\n",
    "        synced_gpus: bool = False,\n",
    "        streamer: Optional[\"BaseStreamer\"] = None,\n",
    "        **model_kwargs,\n",
    "    ) -> Union[GreedySearchOutput, torch.LongTensor]:\n",
    "        # init values\n",
    "        logits_processor = LogitsProcessorList()\n",
    "        stopping_criteria = self.stopping_criteria\n",
    "        pad_token_id = self.generation_config.pad_token_id\n",
    "        eos_token_id = self.generation_config.eos_token_id\n",
    "        if isinstance(eos_token_id, int):\n",
    "            eos_token_id = [eos_token_id]\n",
    "        eos_token_id_tensor = torch.tensor(eos_token_id).to(input_ids.device) if eos_token_id is not None else None\n",
    "        output_scores = output_scores if output_scores is not None else self.generation_config.output_scores\n",
    "        output_attentions = (\n",
    "            output_attentions if output_attentions is not None else self.generation_config.output_attentions\n",
    "        )\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.generation_config.output_hidden_states\n",
    "        )\n",
    "        return_dict_in_generate = (\n",
    "            return_dict_in_generate\n",
    "            if return_dict_in_generate is not None\n",
    "            else self.generation_config.return_dict_in_generate\n",
    "        )\n",
    "    \n",
    "        # init attention / hidden states / scores tuples\n",
    "        scores = () if (return_dict_in_generate and output_scores) else None\n",
    "    \n",
    "        # keep track of which sequences are already finished\n",
    "        unfinished_sequences = torch.ones(input_ids.shape[0], dtype=torch.long, device=input_ids.device)\n",
    "        \n",
    "        this_peer_finished = False  # used by synced_gpus only\n",
    "        \n",
    "        model_kwargs_list = [{'use_cache': True, \n",
    "                              'attention_mask': attention_mask, \n",
    "                              'encoder_outputs':encoder_outputs} for encoder_outputs in encoder_outputs_list]\n",
    "        \n",
    "        decoder_hidden_states_list = [() for _ in range(len(self.models))]\n",
    "        \n",
    "        while True:\n",
    "            # prepare model inputs\n",
    "            # model_inputs = self.prepare_inputs_for_generation(input_ids, **model_kwargs)\n",
    "            model_inputs_list = [self.prepare_inputs_for_generation(input_ids, **model_kwargs) for model_kwargs in model_kwargs_list]\n",
    "            \n",
    "            outputs_list = []\n",
    "            for m, model_inputs in zip(self.models, model_inputs_list):\n",
    "                outputs_list.append(m(\n",
    "                    **model_inputs,\n",
    "                    return_dict=True,\n",
    "                    output_attentions=output_attentions,\n",
    "                    output_hidden_states=output_hidden_states,\n",
    "                ))\n",
    "            \n",
    "            # next_token_logits = outputs.logits[:, -1, :]\n",
    "            next_token_logits = torch.stack([o.logits[:, -1, :] for o in outputs_list]).mean(0)\n",
    "    \n",
    "            # pre-process distribution\n",
    "            next_tokens_scores = logits_processor(input_ids, next_token_logits)\n",
    "            \n",
    "            # Store scores, attentions and hidden_states when required\n",
    "            if return_dict_in_generate:\n",
    "                if output_scores:\n",
    "                    scores += (next_tokens_scores,)\n",
    "                \n",
    "                if output_hidden_states:\n",
    "                    for ii in range(len(model_kwargs_list)):\n",
    "                        decoder_hidden_states_list[ii] += (\n",
    "                            (outputs_list[ii].decoder_hidden_states,)\n",
    "                            if self.config.is_encoder_decoder\n",
    "                            else (outputs_list[ii].hidden_states,)\n",
    "                        )\n",
    "        \n",
    "            # argmax\n",
    "            next_tokens = torch.argmax(next_tokens_scores, dim=-1)\n",
    "            \n",
    "            # finished sentences should have their next token be a padding token\n",
    "            if eos_token_id is not None:\n",
    "                if pad_token_id is None:\n",
    "                    raise ValueError(\"If `eos_token_id` is defined, make sure that `pad_token_id` is defined.\")\n",
    "                next_tokens = next_tokens * unfinished_sequences + pad_token_id * (1 - unfinished_sequences)\n",
    "            \n",
    "            # update generated ids, model inputs, and length for next step\n",
    "            input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)\n",
    "\n",
    "            for ii in range(len(model_kwargs_list)):\n",
    "                model_kwargs_list[ii] = self.models[ii]._update_model_kwargs_for_generation(\n",
    "                                            outputs_list[ii], model_kwargs_list[ii], is_encoder_decoder=self.config.is_encoder_decoder\n",
    "                                        )\n",
    "            \n",
    "            # if eos_token was found in one sentence, set sentence to finished\n",
    "            if eos_token_id_tensor is not None:\n",
    "                unfinished_sequences = unfinished_sequences.mul(\n",
    "                    next_tokens.tile(eos_token_id_tensor.shape[0], 1).ne(eos_token_id_tensor.unsqueeze(1)).prod(dim=0)\n",
    "                )\n",
    "    \n",
    "                # stop when each sentence is finished\n",
    "                if unfinished_sequences.max() == 0:\n",
    "                    this_peer_finished = True\n",
    "    \n",
    "            # stop if we exceed the maximum length\n",
    "            if stopping_criteria(input_ids, scores):\n",
    "                this_peer_finished = True\n",
    "    \n",
    "            if this_peer_finished:\n",
    "                break\n",
    "            \n",
    "        return GreedySearchEncoderDecoderOutput(\n",
    "            sequences=input_ids,\n",
    "            scores=scores,\n",
    "            #attentions=decoder_attentions,\n",
    "            decoder_hidden_states=decoder_hidden_states_list,  # not sure if decoder hidden states if stored correctly, reference original code\n",
    "            encoder_hidden_states=encoder_outputs_list, \n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class EnsembleNet(nn.Module):\n",
    "\n",
    "    def __init__(self, models, cfg):\n",
    "        super(EnsembleNet, self).__init__()\n",
    "\n",
    "        self.cfg = cfg\n",
    "        \n",
    "#         for t, wtsnm in enumerate(cfg.pretrained_weights_blend):\n",
    "#             print(f'Loading {wtsnm}')\n",
    "#             wts = torch.load(wtsnm, map_location=torch.device('cpu'))\n",
    "#             if 'model' in wts:\n",
    "#                 wts = wts['model']\n",
    "#             models[t].load_state_dict(wts, strict = False)\n",
    "            \n",
    "        backbones = [m.backbone for m in models]\n",
    "        self.chart_classifiers = torch.nn.ModuleList([m.chart_classifier for m in models])\n",
    "        self.criterion = models[0].criterion\n",
    "        self.backbones = Pix2StructGreedySearch(backbones, max_length=cfg.max_label_length)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        \n",
    "        encoding = {k:v[:,0] for k,v in batch.items() if k in ['flattened_patches', 'attention_mask']}\n",
    "        \n",
    "        predictions = self.backbones(**encoding)\n",
    "        \n",
    "#         logits_table = predictions.sequences #[:,1:]\n",
    "        # tokenizer.batch_decode(logits_table)\n",
    "        \n",
    "        logits_chart = torch.stack([m(enc.last_hidden_state[:, 0]) for m, enc in zip(self.chart_classifiers, predictions.encoder_hidden_states)]).mean(0)\n",
    "        \n",
    "        return predictions, logits_chart\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b06e0f4",
   "metadata": {
    "papermill": {
     "duration": 0.016753,
     "end_time": "2023-06-21T14:57:24.650776",
     "exception": false,
     "start_time": "2023-06-21T14:57:24.634023",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Scatter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "001ee12d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:57:24.686841Z",
     "iopub.status.busy": "2023-06-21T14:57:24.686444Z",
     "iopub.status.idle": "2023-06-21T14:59:26.828841Z",
     "shell.execute_reply": "2023-06-21T14:59:26.827661Z"
    },
    "papermill": {
     "duration": 122.163282,
     "end_time": "2023-06-21T14:59:26.831255",
     "exception": false,
     "start_time": "2023-06-21T14:57:24.667973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfg_ch_7_2048 mdl_dh_08O ds_dh_08O google/deplot False None\n",
      "/kaggle/input/benetech-cfg-ch-18-ff/fold-1/checkpoint_last_seed231088.pth\n",
      "/kaggle/input/benetech-cfg-ch-18-ff/fold-1/checkpoint_last_seed747128.pth\n",
      "/kaggle/input/benetech-cfg-ch-18b-ff/fold-1/checkpoint_last_seed298682.pth\n",
      "/kaggle/input/benetech-cfg-ch-18c-ff/fold-1/checkpoint_last_seed712261.pth\n",
      "loading dict\n",
      "loading dict\n",
      "loading dict\n",
      "loading dict\n",
      "running inference\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7820d49794f846029f78d637034a0ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'scatter' in predicted_chart_types:\n",
    "\n",
    "    test_df_scatter = test_df[test_df['chart_type_pred'] == 'scatter'].copy()\n",
    "    name = 'cfg_ch_7_2048'\n",
    "\n",
    "    cfg = get_cfg(name)\n",
    "    cfg.backbone = '/kaggle/input/benetech-deplot/google/deplot/'\n",
    "    cfg.data_folder = DATA_FOLDER\n",
    "    cfg.batch_size = 4\n",
    "    cfg.model = \"mdl_dh_08I_val\"\n",
    "    cfg.post_process_pipeline =  \"pp_dh_05B\"\n",
    "    cfg.pretrained_weights_strict = False\n",
    "    cfg.num_beams=1\n",
    "    cfg.temperature=1\n",
    "    cfg.top_k=1\n",
    "    cfg.max_label_length = 512\n",
    "#     cfg.post_process_pipeline = 'pp_dh_01J'\n",
    "    test_dl, batch_to_device = get_dl(test_df_scatter, cfg)\n",
    "    test_dl.dataset.processor.image_processor.is_vqa = False\n",
    "\n",
    "    state_dict_fps = sorted(glob.glob('/kaggle/input/benetech-cfg-ch-18-ff/*/check*'))[:2]\n",
    "    state_dict_fps += sorted(glob.glob('/kaggle/input/benetech-cfg-ch-18b-ff/*/check*'))[:1]\n",
    "    state_dict_fps += sorted(glob.glob('/kaggle/input/benetech-cfg-ch-18c-ff/*/check*'))[:1]\n",
    "    \n",
    "    print('\\n'.join(state_dict_fps))\n",
    "    ens_net = EnsembleNet(get_nets(cfg,state_dict_fps), cfg)\n",
    "\n",
    "    pp = importlib.import_module(cfg.post_process_pipeline)\n",
    "    \n",
    "    print('running inference')\n",
    "    # https://huggingface.co/docs/transformers/main_classes/text_generation\n",
    "    logits_charts = []\n",
    "    logits_tables = []\n",
    "    with torch.inference_mode():\n",
    "        for tt, batch in tqdm(enumerate(test_dl), total = len(test_dl)):\n",
    "            batch = batch_to_device(batch,DEVICE)\n",
    "            #encoding = {k:v[:,0].half() for k,v in batch.items() if k in ['flattened_patches', 'attention_mask']}\n",
    "#             encoding = {k:v[:,0] for k,v in batch.items() if k in ['flattened_patches', 'attention_mask']}\n",
    "#             predictions = nets[0].backbone.generate(**encoding, \n",
    "#                                                     max_new_tokens=cfg.max_label_length, \n",
    "#                                                     early_stopping=True,\n",
    "#                                                     pad_token_id=test_dl.dataset.processor.tokenizer.pad_token_id,\n",
    "#                                                     eos_token_id=test_dl.dataset.processor.tokenizer.eos_token_id,\n",
    "#                                                     use_cache=True,\n",
    "#                                                     num_beams=cfg.num_beams,\n",
    "#                                                     temperature=cfg.temperature,\n",
    "#                                                     top_k=cfg.top_k,\n",
    "#                                                     return_dict_in_generate=True,\n",
    "#                                                     output_hidden_states = True)\n",
    "            predictions, logits_chart = ens_net(batch)\n",
    "            logits_table = predictions.sequences\n",
    "#             logits_chart = nets[0].chart_classifier(predictions.encoder_hidden_states[-1][:,0])\n",
    "#             logits_table = predictions.sequences\n",
    "            padding = (0, cfg.max_label_length - predictions.sequences.size(1))\n",
    "            logits_table  = F.pad(logits_table, padding, mode=\"constant\", value=0)\n",
    "            logits_charts.append(logits_chart)\n",
    "            logits_tables.append(logits_table)\n",
    "    val_data = {}\n",
    "    val_data['logits_chart'] = torch.cat(logits_charts).cpu()\n",
    "    val_data['logits_table'] = torch.cat(logits_tables).cpu()\n",
    "    \n",
    "    sub_df_scatter = pp.post_process_pipeline(cfg, val_data, test_df_scatter)\n",
    "#     sub_df += [sub_df_scatter]\n",
    "    \n",
    "    del ens_net, val_data, test_dl, logits_chart, logits_table\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad65c244",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:59:26.869519Z",
     "iopub.status.busy": "2023-06-21T14:59:26.869100Z",
     "iopub.status.idle": "2023-06-21T14:59:26.873794Z",
     "shell.execute_reply": "2023-06-21T14:59:26.872703Z"
    },
    "papermill": {
     "duration": 0.024361,
     "end_time": "2023-06-21T14:59:26.876253",
     "exception": false,
     "start_time": "2023-06-21T14:59:26.851892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "823f9dd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:59:26.917017Z",
     "iopub.status.busy": "2023-06-21T14:59:26.916469Z",
     "iopub.status.idle": "2023-06-21T14:59:39.556672Z",
     "shell.execute_reply": "2023-06-21T14:59:39.555441Z"
    },
    "papermill": {
     "duration": 12.667224,
     "end_time": "2023-06-21T14:59:39.559658",
     "exception": false,
     "start_time": "2023-06-21T14:59:26.892434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/kaggle/input/benetech-cfg-ch-sunet-13a-ff/fold-1/checkpoint_last_seed123784.pth', '/kaggle/input/benetech-cfg-ch-sunet-13a-ff/fold-1/checkpoint_last_seed571230.pth', '/kaggle/input/benetech-cfg-ch-sunet-13a-ff/fold-1/checkpoint_last_seed665547.pth']\n",
      "cfg_ch_sunet_1d2_b7_ext_v2_aug0f2_ddp2 mdl_ch_sunet_2 ds_ch_sunet_2_v3 tf_efficientnet_b7_ns False None\n",
      "loading dict\n",
      "loading dict\n",
      "loading dict\n"
     ]
    }
   ],
   "source": [
    "CFG = 'cfg_ch_sunet_1d2_b7_ext_v2_aug0f2_ddp2'\n",
    "state_dicts = sorted(glob.glob('/kaggle/input/benetech-cfg-ch-sunet-13a-ff/*/*.pth'))\n",
    "print(state_dicts)\n",
    "\n",
    "cfg = get_cfg(CFG)\n",
    "cfg.test_data_folder = cfg.test_data_folder + 'images/'\n",
    "cfg.val_aug = A.Compose([\n",
    "    A.Resize(768,768)\n",
    "#     A.PadIfNeeded (min_height=256, min_width=940),\n",
    "#     A.LongestMaxSize(cfg.image_width_orig,p=1),\n",
    "#     A.PadIfNeeded(cfg.image_width_orig, cfg.image_height_orig, border_mode=cv2.BORDER_CONSTANT,p=1),\n",
    "#     A.CenterCrop(always_apply=False, p=1.0, height=cfg.image_height, width=cfg.image_width), \n",
    "#     A.Resize(cfg.img_size[0],cfg.img_size[1])\n",
    "])\n",
    "cfg.model = 'mdl_ch_sunet_2_inf'\n",
    "cfg.return_logits = True\n",
    "# cfg.batch_size = 2\n",
    "test_dl, batch_to_device = get_dl(test_df_scatter, cfg)\n",
    "nets = get_nets(cfg,state_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1fa91b32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:59:39.594512Z",
     "iopub.status.busy": "2023-06-21T14:59:39.594137Z",
     "iopub.status.idle": "2023-06-21T14:59:51.191612Z",
     "shell.execute_reply": "2023-06-21T14:59:51.184561Z"
    },
    "papermill": {
     "duration": 11.618097,
     "end_time": "2023-06-21T14:59:51.194602",
     "exception": false,
     "start_time": "2023-06-21T14:59:39.576505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b12dfa80517456aad14865e3b0f9184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "    reader_close()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "\n",
    "    n_preds = []\n",
    "    for batch in tqdm(test_dl):\n",
    "        batch = batch_to_device(batch, 'cuda')\n",
    "        batch_preds = []\n",
    "        for i, net in enumerate(nets):\n",
    "            x_pred = net(batch)['pred_mask'].float()\n",
    "            batch_preds += [x_pred]\n",
    "        batch_preds = torch.stack(batch_preds).mean(0)\n",
    "        x_pooled = F.max_pool2d(batch_preds, kernel_size=cfg.nms_kernel_size, stride=1, padding=cfg.nms_padding)\n",
    "        batch_preds[batch_preds != x_pooled] = 0\n",
    "        n_pred = (batch_preds[:,0] > cfg.n_threshold).sum((1,2)).cpu().numpy()\n",
    "        n_preds += [n_pred]\n",
    "    n_preds = np.concatenate(n_preds)\n",
    "\n",
    "    \n",
    "del nets, test_dl\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1384c740",
   "metadata": {
    "papermill": {
     "duration": 0.029726,
     "end_time": "2023-06-21T14:59:51.253477",
     "exception": false,
     "start_time": "2023-06-21T14:59:51.223751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2055fc50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:59:51.301627Z",
     "iopub.status.busy": "2023-06-21T14:59:51.301205Z",
     "iopub.status.idle": "2023-06-21T14:59:51.307135Z",
     "shell.execute_reply": "2023-06-21T14:59:51.306240Z"
    },
    "papermill": {
     "duration": 0.026954,
     "end_time": "2023-06-21T14:59:51.309126",
     "exception": false,
     "start_time": "2023-06-21T14:59:51.282172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_mean(x):\n",
    "    vals = []\n",
    "    for item in x.split(';'):\n",
    "        try:\n",
    "            vals += [float(item)]\n",
    "        except:\n",
    "            pass\n",
    "    if len(vals) > 0:\n",
    "        m = np.mean(vals)\n",
    "    else:\n",
    "        m = 0\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ce451a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:59:51.343436Z",
     "iopub.status.busy": "2023-06-21T14:59:51.342586Z",
     "iopub.status.idle": "2023-06-21T14:59:51.353051Z",
     "shell.execute_reply": "2023-06-21T14:59:51.352195Z"
    },
    "papermill": {
     "duration": 0.029833,
     "end_time": "2023-06-21T14:59:51.355104",
     "exception": false,
     "start_time": "2023-06-21T14:59:51.325271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load unet count preds\n",
    "oof_df = test_df_scatter[['id']].copy()\n",
    "oof_df['n_pred'] = n_preds\n",
    "oof_df_x = oof_df.copy()\n",
    "oof_df_x['id'] = oof_df_x['id'] + '_x'\n",
    "oof_df_y = oof_df.copy()\n",
    "oof_df_y['id'] = oof_df_y['id'] + '_y'\n",
    "oof_df_xy = pd.concat([oof_df_x,oof_df_y])\n",
    "oof_df_xy = oof_df_xy.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f543a9af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:59:51.389695Z",
     "iopub.status.busy": "2023-06-21T14:59:51.388820Z",
     "iopub.status.idle": "2023-06-21T14:59:51.395932Z",
     "shell.execute_reply": "2023-06-21T14:59:51.394891Z"
    },
    "papermill": {
     "duration": 0.026387,
     "end_time": "2023-06-21T14:59:51.397967",
     "exception": false,
     "start_time": "2023-06-21T14:59:51.371580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 1), (2, 2))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_df_xy.shape, sub_df_scatter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d88cbda3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:59:51.432032Z",
     "iopub.status.busy": "2023-06-21T14:59:51.431118Z",
     "iopub.status.idle": "2023-06-21T14:59:51.447803Z",
     "shell.execute_reply": "2023-06-21T14:59:51.446890Z"
    },
    "papermill": {
     "duration": 0.035604,
     "end_time": "2023-06-21T14:59:51.449926",
     "exception": false,
     "start_time": "2023-06-21T14:59:51.414322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pp_out_scatter = sub_df_scatter.copy()\n",
    "\n",
    "#merge into one df\n",
    "pp_out_scatter['n_current'] = pp_out_scatter['data_series'].apply(lambda x: len(x.split(';')))\n",
    "pp_out_scatter = pp_out_scatter.merge(oof_df_xy[['n_pred']],how='left',left_index=True,right_index=True)\n",
    "\n",
    "## count pp1: cut at n_pred if n_current > n_pred\n",
    "\n",
    "mask = pp_out_scatter['n_current']>pp_out_scatter['n_pred'] #False for nans\n",
    "if mask.sum()> 0:\n",
    "    pp_out_scatter.loc[mask,'data_series'] = pp_out_scatter[mask].apply(lambda x: ';'.join((x['data_series'].split(';')[:int(x['n_pred'])])), axis=1)\n",
    "\n",
    "## count pp2: fill with mean if n_current < n_pred\n",
    "mask2 = pp_out_scatter['n_current']<pp_out_scatter['n_pred'] #False for nans\n",
    "if mask2.sum()> 0:\n",
    "    pp_out_scatter_to_fix = pp_out_scatter.loc[mask2].copy()\n",
    "    pp_out_scatter_to_fix['mean_data_series'] = pp_out_scatter_to_fix['data_series'].apply(lambda x: get_mean(x))\n",
    "    pp_out_scatter_to_fix['data_series'] = pp_out_scatter_to_fix.apply(lambda x: ';'.join(x['data_series'].split(';') + [str(x['mean_data_series'])] * (int(x['n_pred']) - x['n_current'])), axis=1)\n",
    "    pp_out_scatter.loc[mask2, 'data_series'] = pp_out_scatter_to_fix['data_series'].values\n",
    "\n",
    "sub_df_scatter['data_series'] = pp_out_scatter['data_series'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8db1d1f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:59:51.484676Z",
     "iopub.status.busy": "2023-06-21T14:59:51.483811Z",
     "iopub.status.idle": "2023-06-21T14:59:51.488147Z",
     "shell.execute_reply": "2023-06-21T14:59:51.487288Z"
    },
    "papermill": {
     "duration": 0.023372,
     "end_time": "2023-06-21T14:59:51.490142",
     "exception": false,
     "start_time": "2023-06-21T14:59:51.466770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df += [sub_df_scatter]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc92c62",
   "metadata": {
    "papermill": {
     "duration": 0.016149,
     "end_time": "2023-06-21T14:59:51.522557",
     "exception": false,
     "start_time": "2023-06-21T14:59:51.506408",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Vertical Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d00eb6b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T14:59:51.558046Z",
     "iopub.status.busy": "2023-06-21T14:59:51.557723Z",
     "iopub.status.idle": "2023-06-21T15:01:35.114691Z",
     "shell.execute_reply": "2023-06-21T15:01:35.113473Z"
    },
    "papermill": {
     "duration": 103.578274,
     "end_time": "2023-06-21T15:01:35.118093",
     "exception": false,
     "start_time": "2023-06-21T14:59:51.539819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running vertical_bar\n",
      "setting up dataloader and model\n",
      "cfg_ch_7_2048 mdl_dh_08O ds_dh_08O google/deplot False None\n",
      "/kaggle/input/benetech-cfg-ch-19-ff/fold-1/checkpoint_last_seed212431.pth\n",
      "/kaggle/input/benetech-cfg-ch-19-ff/fold-1/checkpoint_last_seed705191.pth\n",
      "/kaggle/input/benetech-cfg-ch-19b-ff/fold-1/checkpoint_last_seed20860.pth\n",
      "/kaggle/input/benetech-cfg-ch-19b-ff/fold-1/checkpoint_last_seed373462.pth\n",
      "loading dict\n",
      "loading dict\n",
      "loading dict\n",
      "loading dict\n",
      "running inference\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1a714d43f04650b076b75209569f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#do vbar\n",
    "if 'vertical_bar' in predicted_chart_types:\n",
    "    \n",
    "    print('running vertical_bar')\n",
    "    print('setting up dataloader and model')\n",
    "    test_df_vb = test_df[test_df['chart_type_pred'] == 'vertical_bar'].copy()\n",
    "    \n",
    "    name = 'cfg_ch_7_2048'\n",
    "\n",
    "    cfg = get_cfg(name)\n",
    "    cfg.backbone = '/kaggle/input/benetech-deplot/google/deplot/'\n",
    "    cfg.data_folder = DATA_FOLDER\n",
    "    cfg.batch_size = 4\n",
    "    cfg.model = \"mdl_dh_08I_val\"\n",
    "    cfg.post_process_pipeline =  \"pp_dh_05B_hist\"\n",
    "    cfg.pretrained_weights_strict = False\n",
    "    cfg.num_beams=1\n",
    "    cfg.temperature=1\n",
    "    cfg.top_k=1\n",
    "    cfg.max_label_length = 512\n",
    "#     cfg.post_process_pipeline = 'pp_dh_01J'\n",
    "    test_dl, batch_to_device = get_dl(test_df_vb, cfg)\n",
    "#     test_dl.dataset.processor.image_processor.is_vqa = False\n",
    "\n",
    "    state_dict_fps = sorted(glob.glob('/kaggle/input/benetech-cfg-ch-19-ff/*/check*'))[:2]\n",
    "    state_dict_fps += sorted(glob.glob('/kaggle/input/benetech-cfg-ch-19b-ff/*/check*'))[:2]\n",
    "    print('\\n'.join(state_dict_fps))\n",
    "\n",
    "    ens_net = EnsembleNet(get_nets(cfg,state_dict_fps), cfg)\n",
    "\n",
    "    pp = importlib.import_module(cfg.post_process_pipeline)\n",
    "    \n",
    "    print('running inference')\n",
    "    # https://huggingface.co/docs/transformers/main_classes/text_generation\n",
    "    logits_charts = []\n",
    "    logits_tables = []\n",
    "    with torch.inference_mode():\n",
    "        for tt, batch in tqdm(enumerate(test_dl), total = len(test_dl)):\n",
    "            batch = batch_to_device(batch,DEVICE)\n",
    "            #encoding = {k:v[:,0].half() for k,v in batch.items() if k in ['flattened_patches', 'attention_mask']}\n",
    "#             encoding = {k:v[:,0] for k,v in batch.items() if k in ['flattened_patches', 'attention_mask']}\n",
    "#             predictions = nets[0].backbone.generate(**encoding, \n",
    "#                                                     max_new_tokens=cfg.max_label_length, \n",
    "#                                                     early_stopping=True,\n",
    "#                                                     pad_token_id=test_dl.dataset.processor.tokenizer.pad_token_id,\n",
    "#                                                     eos_token_id=test_dl.dataset.processor.tokenizer.eos_token_id,\n",
    "#                                                     use_cache=True,\n",
    "#                                                     num_beams=cfg.num_beams,\n",
    "#                                                     temperature=cfg.temperature,\n",
    "#                                                     top_k=cfg.top_k,\n",
    "#                                                     return_dict_in_generate=True,\n",
    "#                                                     output_hidden_states = True)\n",
    "            predictions, logits_chart = ens_net(batch)\n",
    "            logits_table = predictions.sequences\n",
    "#             logits_chart = nets[0].chart_classifier(predictions.encoder_hidden_states[-1][:,0])\n",
    "#             logits_table = predictions.sequences\n",
    "            padding = (0, cfg.max_label_length - predictions.sequences.size(1))\n",
    "            logits_table  = F.pad(logits_table, padding, mode=\"constant\", value=0)\n",
    "            logits_charts.append(logits_chart)\n",
    "            logits_tables.append(logits_table)\n",
    "    val_data = {}\n",
    "    val_data['logits_chart'] = torch.cat(logits_charts).cpu()\n",
    "    val_data['logits_table'] = torch.cat(logits_tables).cpu()\n",
    "    \n",
    "    \n",
    "    sub_df_vb = pp.post_process_pipeline(cfg, val_data, test_df_vb)\n",
    "    sub_df += [sub_df_vb]\n",
    "    \n",
    "    \n",
    "    del ens_net, val_data, test_dl, logits_charts, logits_tables\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab859eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T20:13:07.263146Z",
     "iopub.status.busy": "2023-06-09T20:13:07.262787Z",
     "iopub.status.idle": "2023-06-09T20:13:07.269Z",
     "shell.execute_reply": "2023-06-09T20:13:07.266427Z",
     "shell.execute_reply.started": "2023-06-09T20:13:07.263118Z"
    },
    "papermill": {
     "duration": 0.02417,
     "end_time": "2023-06-21T15:01:35.169519",
     "exception": false,
     "start_time": "2023-06-21T15:01:35.145349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Horizontal Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f3815bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T15:01:35.221519Z",
     "iopub.status.busy": "2023-06-21T15:01:35.220992Z",
     "iopub.status.idle": "2023-06-21T15:01:35.239938Z",
     "shell.execute_reply": "2023-06-21T15:01:35.238947Z"
    },
    "papermill": {
     "duration": 0.049496,
     "end_time": "2023-06-21T15:01:35.242660",
     "exception": false,
     "start_time": "2023-06-21T15:01:35.193164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'horizontal_bar' in predicted_chart_types:\n",
    "    \n",
    "    print('running vertical_bar')\n",
    "    print('setting up dataloader and model')\n",
    "    test_df_hb = test_df[test_df['chart_type_pred'] == 'horizontal_bar'].copy()\n",
    "    \n",
    "    name = 'cfg_ch_7_2048'\n",
    "\n",
    "    cfg = get_cfg(name)\n",
    "    cfg.backbone = '/kaggle/input/benetech-deplot/google/deplot/'\n",
    "    cfg.data_folder = DATA_FOLDER\n",
    "    cfg.batch_size = 4\n",
    "    cfg.model = \"mdl_dh_08I_val\"\n",
    "    cfg.post_process_pipeline =  \"pp_dh_05B\"\n",
    "    cfg.pretrained_weights_strict = False\n",
    "    cfg.num_beams=1\n",
    "    cfg.temperature=1\n",
    "    cfg.top_k=1\n",
    "    cfg.max_label_length = 512\n",
    "#     cfg.post_process_pipeline = 'pp_dh_01J'\n",
    "    test_dl, batch_to_device = get_dl(test_df_hb, cfg)\n",
    "    test_dl.dataset.processor.image_processor.is_vqa = False\n",
    "\n",
    "    state_dict_fps = sorted(glob.glob('/kaggle/input/benetech-cfg-ch-18-ff/*/check*'))[:2]\n",
    "    state_dict_fps += sorted(glob.glob('/kaggle/input/benetech-cfg-ch-18b-ff/*/check*'))[:1]\n",
    "    state_dict_fps += sorted(glob.glob('/kaggle/input/benetech-cfg-ch-18c-ff/*/check*'))[:1]\n",
    "    \n",
    "    print('\\n'.join(state_dict_fps))\n",
    "    ens_net = EnsembleNet(get_nets(cfg,state_dict_fps), cfg)\n",
    "\n",
    "    pp = importlib.import_module(cfg.post_process_pipeline)\n",
    "    \n",
    "    print('running inference')\n",
    "    # https://huggingface.co/docs/transformers/main_classes/text_generation\n",
    "    logits_charts = []\n",
    "    logits_tables = []\n",
    "    with torch.inference_mode():\n",
    "        for tt, batch in tqdm(enumerate(test_dl), total = len(test_dl)):\n",
    "            batch = batch_to_device(batch,DEVICE)\n",
    "            #encoding = {k:v[:,0].half() for k,v in batch.items() if k in ['flattened_patches', 'attention_mask']}\n",
    "#             encoding = {k:v[:,0] for k,v in batch.items() if k in ['flattened_patches', 'attention_mask']}\n",
    "#             predictions = nets[0].backbone.generate(**encoding, \n",
    "#                                                     max_new_tokens=cfg.max_label_length, \n",
    "#                                                     early_stopping=True,\n",
    "#                                                     pad_token_id=test_dl.dataset.processor.tokenizer.pad_token_id,\n",
    "#                                                     eos_token_id=test_dl.dataset.processor.tokenizer.eos_token_id,\n",
    "#                                                     use_cache=True,\n",
    "#                                                     num_beams=cfg.num_beams,\n",
    "#                                                     temperature=cfg.temperature,\n",
    "#                                                     top_k=cfg.top_k,\n",
    "#                                                     return_dict_in_generate=True,\n",
    "#                                                     output_hidden_states = True)\n",
    "            predictions, logits_chart = ens_net(batch)\n",
    "            logits_table = predictions.sequences\n",
    "#             logits_chart = nets[0].chart_classifier(predictions.encoder_hidden_states[-1][:,0])\n",
    "#             logits_table = predictions.sequences\n",
    "            padding = (0, cfg.max_label_length - predictions.sequences.size(1))\n",
    "            logits_table  = F.pad(logits_table, padding, mode=\"constant\", value=0)\n",
    "            logits_charts.append(logits_chart)\n",
    "            logits_tables.append(logits_table)\n",
    "    val_data = {}\n",
    "    val_data['logits_chart'] = torch.cat(logits_charts).cpu()\n",
    "    val_data['logits_table'] = torch.cat(logits_tables).cpu()\n",
    "    \n",
    "    sub_df_hb = pp.post_process_pipeline(cfg, val_data, test_df_hb)\n",
    "    sub_df += [sub_df_hb]\n",
    "    \n",
    "    del ens_net, val_data, test_dl, logits_charts, logits_tables\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c849fb0",
   "metadata": {
    "papermill": {
     "duration": 0.025936,
     "end_time": "2023-06-21T15:01:35.293645",
     "exception": false,
     "start_time": "2023-06-21T15:01:35.267709",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1f0f883",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T15:01:35.347540Z",
     "iopub.status.busy": "2023-06-21T15:01:35.347070Z",
     "iopub.status.idle": "2023-06-21T15:03:06.405383Z",
     "shell.execute_reply": "2023-06-21T15:03:06.404254Z"
    },
    "papermill": {
     "duration": 91.088169,
     "end_time": "2023-06-21T15:03:06.408165",
     "exception": false,
     "start_time": "2023-06-21T15:01:35.319996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfg_ch_7_2048 mdl_dh_08O ds_dh_08O google/deplot False None\n",
      "/kaggle/input/benetech-cfg-ch-18-ff/fold-1/checkpoint_last_seed231088.pth\n",
      "/kaggle/input/benetech-cfg-ch-18-ff/fold-1/checkpoint_last_seed747128.pth\n",
      "/kaggle/input/benetech-cfg-ch-18b-ff/fold-1/checkpoint_last_seed298682.pth\n",
      "/kaggle/input/benetech-cfg-ch-18c-ff/fold-1/checkpoint_last_seed712261.pth\n",
      "loading dict\n",
      "loading dict\n",
      "loading dict\n",
      "loading dict\n",
      "running inference\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d42c6b7574479f92e8e6445bc832e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'line' in predicted_chart_types:\n",
    "\n",
    "    test_df_line = test_df[test_df['chart_type_pred'] == 'line'].copy()\n",
    "\n",
    "    \n",
    "    name = 'cfg_ch_7_2048'\n",
    "\n",
    "    cfg = get_cfg(name)\n",
    "    cfg.backbone = '/kaggle/input/benetech-deplot/google/deplot/'\n",
    "    cfg.data_folder = DATA_FOLDER\n",
    "    cfg.batch_size = 4\n",
    "    cfg.model = \"mdl_dh_08I_val\"\n",
    "    cfg.post_process_pipeline =  \"pp_dh_05B\"\n",
    "    cfg.pretrained_weights_strict = False\n",
    "    cfg.num_beams=1\n",
    "    cfg.temperature=1\n",
    "    cfg.top_k=1\n",
    "    cfg.max_label_length = 512\n",
    "#     cfg.post_process_pipeline = 'pp_dh_01J'\n",
    "    test_dl, batch_to_device = get_dl(test_df_line, cfg)\n",
    "    test_dl.dataset.processor.image_processor.is_vqa = False\n",
    "\n",
    "    state_dict_fps = sorted(glob.glob('/kaggle/input/benetech-cfg-ch-18-ff/*/check*'))[:2]\n",
    "    state_dict_fps += sorted(glob.glob('/kaggle/input/benetech-cfg-ch-18b-ff/*/check*'))[:1]\n",
    "    state_dict_fps += sorted(glob.glob('/kaggle/input/benetech-cfg-ch-18c-ff/*/check*'))[:1]\n",
    "    \n",
    "    print('\\n'.join(state_dict_fps))\n",
    "    ens_net = EnsembleNet(get_nets(cfg,state_dict_fps), cfg)\n",
    "\n",
    "    pp = importlib.import_module(cfg.post_process_pipeline)\n",
    "    \n",
    "    print('running inference')\n",
    "    # https://huggingface.co/docs/transformers/main_classes/text_generation\n",
    "    logits_charts = []\n",
    "    logits_tables = []\n",
    "    with torch.inference_mode():\n",
    "        for tt, batch in tqdm(enumerate(test_dl), total = len(test_dl)):\n",
    "            batch = batch_to_device(batch,DEVICE)\n",
    "            #encoding = {k:v[:,0].half() for k,v in batch.items() if k in ['flattened_patches', 'attention_mask']}\n",
    "#             encoding = {k:v[:,0] for k,v in batch.items() if k in ['flattened_patches', 'attention_mask']}\n",
    "#             predictions = nets[0].backbone.generate(**encoding, \n",
    "#                                                     max_new_tokens=cfg.max_label_length, \n",
    "#                                                     early_stopping=True,\n",
    "#                                                     pad_token_id=test_dl.dataset.processor.tokenizer.pad_token_id,\n",
    "#                                                     eos_token_id=test_dl.dataset.processor.tokenizer.eos_token_id,\n",
    "#                                                     use_cache=True,\n",
    "#                                                     num_beams=cfg.num_beams,\n",
    "#                                                     temperature=cfg.temperature,\n",
    "#                                                     top_k=cfg.top_k,\n",
    "#                                                     return_dict_in_generate=True,\n",
    "#                                                     output_hidden_states = True)\n",
    "            predictions, logits_chart = ens_net(batch)\n",
    "            logits_table = predictions.sequences\n",
    "#             logits_chart = nets[0].chart_classifier(predictions.encoder_hidden_states[-1][:,0])\n",
    "#             logits_table = predictions.sequences\n",
    "            padding = (0, cfg.max_label_length - predictions.sequences.size(1))\n",
    "            logits_table  = F.pad(logits_table, padding, mode=\"constant\", value=0)\n",
    "            logits_charts.append(logits_chart)\n",
    "            logits_tables.append(logits_table)\n",
    "    val_data = {}\n",
    "    val_data['logits_chart'] = torch.cat(logits_charts).cpu()\n",
    "    val_data['logits_table'] = torch.cat(logits_tables).cpu()\n",
    "    \n",
    "    sub_df_line = pp.post_process_pipeline(cfg, val_data, test_df_line)\n",
    "    sub_df += [sub_df_line]\n",
    "    \n",
    "    del ens_net, val_data, test_dl, logits_charts, logits_tables\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727ed43d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-09T20:30:08.556428Z",
     "iopub.status.idle": "2023-06-09T20:30:08.557194Z",
     "shell.execute_reply": "2023-06-09T20:30:08.556952Z",
     "shell.execute_reply.started": "2023-06-09T20:30:08.556929Z"
    },
    "papermill": {
     "duration": 0.019177,
     "end_time": "2023-06-21T15:03:06.447094",
     "exception": false,
     "start_time": "2023-06-21T15:03:06.427917",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd11784d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T15:03:06.485230Z",
     "iopub.status.busy": "2023-06-21T15:03:06.484858Z",
     "iopub.status.idle": "2023-06-21T15:03:06.498951Z",
     "shell.execute_reply": "2023-06-21T15:03:06.497903Z"
    },
    "papermill": {
     "duration": 0.036799,
     "end_time": "2023-06-21T15:03:06.501852",
     "exception": false,
     "start_time": "2023-06-21T15:03:06.465053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'dot' in predicted_chart_types:\n",
    "    \n",
    "    test_df_dot = test_df[test_df['chart_type_pred'] == 'dot'].copy()\n",
    "    \n",
    "    name = 'cfg_ch_7_2048'\n",
    "\n",
    "    cfg = get_cfg(name)\n",
    "    cfg.backbone = '/kaggle/input/benetech-deplot/google/deplot/'\n",
    "    cfg.data_folder = DATA_FOLDER\n",
    "    cfg.batch_size = 4\n",
    "    cfg.model = \"mdl_dh_08I_val\"\n",
    "    cfg.post_process_pipeline =  \"pp_dh_05B\"\n",
    "    cfg.pretrained_weights_strict = False\n",
    "    cfg.num_beams=1\n",
    "    cfg.temperature=1\n",
    "    cfg.top_k=1\n",
    "    cfg.max_label_length = 512\n",
    "#     cfg.post_process_pipeline = 'pp_dh_01J'\n",
    "    test_dl, batch_to_device = get_dl(test_df_dot, cfg)\n",
    "    test_dl.dataset.processor.image_processor.is_vqa = False\n",
    "\n",
    "    state_dict_fps = sorted(glob.glob('/kaggle/input/benetech-cfg-ch-18-ff/*/check*'))[:2]\n",
    "    state_dict_fps += sorted(glob.glob('/kaggle/input/benetech-cfg-ch-18b-ff/*/check*'))[:1]\n",
    "    state_dict_fps += sorted(glob.glob('/kaggle/input/benetech-cfg-ch-18c-ff/*/check*'))[:1]\n",
    "    \n",
    "    print('\\n'.join(state_dict_fps))\n",
    "    ens_net = EnsembleNet(get_nets(cfg,state_dict_fps), cfg)\n",
    "\n",
    "    pp = importlib.import_module(cfg.post_process_pipeline)\n",
    "    \n",
    "    print('running inference')\n",
    "    # https://huggingface.co/docs/transformers/main_classes/text_generation\n",
    "    logits_charts = []\n",
    "    logits_tables = []\n",
    "    with torch.inference_mode():\n",
    "        for tt, batch in tqdm(enumerate(test_dl), total = len(test_dl)):\n",
    "            batch = batch_to_device(batch,DEVICE)\n",
    "            #encoding = {k:v[:,0].half() for k,v in batch.items() if k in ['flattened_patches', 'attention_mask']}\n",
    "#             encoding = {k:v[:,0] for k,v in batch.items() if k in ['flattened_patches', 'attention_mask']}\n",
    "#             predictions = nets[0].backbone.generate(**encoding, \n",
    "#                                                     max_new_tokens=cfg.max_label_length, \n",
    "#                                                     early_stopping=True,\n",
    "#                                                     pad_token_id=test_dl.dataset.processor.tokenizer.pad_token_id,\n",
    "#                                                     eos_token_id=test_dl.dataset.processor.tokenizer.eos_token_id,\n",
    "#                                                     use_cache=True,\n",
    "#                                                     num_beams=cfg.num_beams,\n",
    "#                                                     temperature=cfg.temperature,\n",
    "#                                                     top_k=cfg.top_k,\n",
    "#                                                     return_dict_in_generate=True,\n",
    "#                                                     output_hidden_states = True)\n",
    "            predictions, logits_chart = ens_net(batch)\n",
    "            logits_table = predictions.sequences\n",
    "#             logits_chart = nets[0].chart_classifier(predictions.encoder_hidden_states[-1][:,0])\n",
    "#             logits_table = predictions.sequences\n",
    "            padding = (0, cfg.max_label_length - predictions.sequences.size(1))\n",
    "            logits_table  = F.pad(logits_table, padding, mode=\"constant\", value=0)\n",
    "            logits_charts.append(logits_chart)\n",
    "            logits_tables.append(logits_table)\n",
    "    val_data = {}\n",
    "    val_data['logits_chart'] = torch.cat(logits_charts).cpu()\n",
    "    val_data['logits_table'] = torch.cat(logits_tables).cpu()\n",
    "    \n",
    "    sub_df_dot = pp.post_process_pipeline(cfg, val_data, test_df_dot)\n",
    "    sub_df += [sub_df_dot]\n",
    "    \n",
    "    del ens_net, val_data, test_dl, logits_charts, logits_tables\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "361f4cc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T15:03:06.539032Z",
     "iopub.status.busy": "2023-06-21T15:03:06.538689Z",
     "iopub.status.idle": "2023-06-21T15:03:06.544609Z",
     "shell.execute_reply": "2023-06-21T15:03:06.543517Z"
    },
    "papermill": {
     "duration": 0.027538,
     "end_time": "2023-06-21T15:03:06.547035",
     "exception": false,
     "start_time": "2023-06-21T15:03:06.519497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df = pd.concat(sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9915ed09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T15:03:06.584439Z",
     "iopub.status.busy": "2023-06-21T15:03:06.584107Z",
     "iopub.status.idle": "2023-06-21T15:03:06.600275Z",
     "shell.execute_reply": "2023-06-21T15:03:06.598910Z"
    },
    "papermill": {
     "duration": 0.037972,
     "end_time": "2023-06-21T15:03:06.603177",
     "exception": false,
     "start_time": "2023-06-21T15:03:06.565205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_series</th>\n",
       "      <th>chart_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00f5404753cf_x</th>\n",
       "      <td>5;5;5;6;6;6;7;7;7;8;8;8;9;9;9;10;10;10;11;11;1...</td>\n",
       "      <td>scatter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00f5404753cf_y</th>\n",
       "      <td>11;12;14;12;13;14;14;16;17;17;18;19;20;21;22;2...</td>\n",
       "      <td>scatter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00dcf883a459_x</th>\n",
       "      <td>Group 1;Group 2</td>\n",
       "      <td>vertical_bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00dcf883a459_y</th>\n",
       "      <td>3.6;8.4</td>\n",
       "      <td>vertical_bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01b45b831589_x</th>\n",
       "      <td>21-Feb;22-Feb;23-Feb;24-Feb;25-Feb;26-Feb;27-F...</td>\n",
       "      <td>vertical_bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01b45b831589_y</th>\n",
       "      <td>90000;150000;170000;175000;135000;100000;0;400...</td>\n",
       "      <td>vertical_bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000b92c3b098_x</th>\n",
       "      <td>0;6;12;18;24</td>\n",
       "      <td>line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000b92c3b098_y</th>\n",
       "      <td>0.0;-0.7;-1.4;-2.1;-2.8</td>\n",
       "      <td>line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>007a18eb4e09_x</th>\n",
       "      <td>0.0;0.4;0.8;1.2;1.6;2.0;2.4</td>\n",
       "      <td>line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>007a18eb4e09_y</th>\n",
       "      <td>0.013278;0.013278;0.013282;0.013272;0.013279;0...</td>\n",
       "      <td>line</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      data_series  \\\n",
       "id                                                                  \n",
       "00f5404753cf_x  5;5;5;6;6;6;7;7;7;8;8;8;9;9;9;10;10;10;11;11;1...   \n",
       "00f5404753cf_y  11;12;14;12;13;14;14;16;17;17;18;19;20;21;22;2...   \n",
       "00dcf883a459_x                                    Group 1;Group 2   \n",
       "00dcf883a459_y                                            3.6;8.4   \n",
       "01b45b831589_x  21-Feb;22-Feb;23-Feb;24-Feb;25-Feb;26-Feb;27-F...   \n",
       "01b45b831589_y  90000;150000;170000;175000;135000;100000;0;400...   \n",
       "000b92c3b098_x                                       0;6;12;18;24   \n",
       "000b92c3b098_y                            0.0;-0.7;-1.4;-2.1;-2.8   \n",
       "007a18eb4e09_x                        0.0;0.4;0.8;1.2;1.6;2.0;2.4   \n",
       "007a18eb4e09_y  0.013278;0.013278;0.013282;0.013272;0.013279;0...   \n",
       "\n",
       "                  chart_type  \n",
       "id                            \n",
       "00f5404753cf_x       scatter  \n",
       "00f5404753cf_y       scatter  \n",
       "00dcf883a459_x  vertical_bar  \n",
       "00dcf883a459_y  vertical_bar  \n",
       "01b45b831589_x  vertical_bar  \n",
       "01b45b831589_y  vertical_bar  \n",
       "000b92c3b098_x          line  \n",
       "000b92c3b098_y          line  \n",
       "007a18eb4e09_x          line  \n",
       "007a18eb4e09_y          line  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.to_csv(\"submission.csv\")\n",
    "pd.set_option('display.width', None)\n",
    "sub_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50e9d663",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T15:03:06.648107Z",
     "iopub.status.busy": "2023-06-21T15:03:06.647709Z",
     "iopub.status.idle": "2023-06-21T15:03:07.823559Z",
     "shell.execute_reply": "2023-06-21T15:03:07.822337Z"
    },
    "papermill": {
     "duration": 1.203352,
     "end_time": "2023-06-21T15:03:07.826397",
     "exception": false,
     "start_time": "2023-06-21T15:03:06.623045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,data_series,chart_type\r\n",
      "00f5404753cf_x,5;5;5;6;6;6;7;7;7;8;8;8;9;9;9;10;10;10;11;11;11;11;12;12;12;13;13;13;14;14;14;15;15;15;16;16;16;10.513513513513514,scatter\r\n",
      "00f5404753cf_y,11;12;14;12;13;14;14;16;17;17;18;19;20;21;22;21;22;23;21;22;23;24;23;24;26;24;26;27;25;27;28;26;27;29;29;30;31;21.56756756756757,scatter\r\n",
      "00dcf883a459_x,Group 1;Group 2,vertical_bar\r\n",
      "00dcf883a459_y,3.6;8.4,vertical_bar\r\n",
      "01b45b831589_x,21-Feb;22-Feb;23-Feb;24-Feb;25-Feb;26-Feb;27-Feb;28-Feb;29-Feb;01-Mar;02-Mar;03-Mar;04-Mar;05-Mar;06-Mar;07-Mar;08-Mar;09-Mar;10-Mar,vertical_bar\r\n",
      "01b45b831589_y,90000;150000;170000;175000;135000;100000;0;40000;60000;65000;55000;45000;65000;80000;80000;105000;130000;100000;10000,vertical_bar\r\n",
      "000b92c3b098_x,0;6;12;18;24,line\r\n",
      "000b92c3b098_y,0.0;-0.7;-1.4;-2.1;-2.8,line\r\n",
      "007a18eb4e09_x,0.0;0.4;0.8;1.2;1.6;2.0;2.4,line\r\n"
     ]
    }
   ],
   "source": [
    "!head submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07790122",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T15:03:07.865841Z",
     "iopub.status.busy": "2023-06-21T15:03:07.865112Z",
     "iopub.status.idle": "2023-06-21T15:03:07.870352Z",
     "shell.execute_reply": "2023-06-21T15:03:07.869272Z"
    },
    "papermill": {
     "duration": 0.02756,
     "end_time": "2023-06-21T15:03:07.872526",
     "exception": false,
     "start_time": "2023-06-21T15:03:07.844966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c078aa96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T15:03:07.910816Z",
     "iopub.status.busy": "2023-06-21T15:03:07.910475Z",
     "iopub.status.idle": "2023-06-21T15:03:07.918688Z",
     "shell.execute_reply": "2023-06-21T15:03:07.917588Z"
    },
    "papermill": {
     "duration": 0.030238,
     "end_time": "2023-06-21T15:03:07.921193",
     "exception": false,
     "start_time": "2023-06-21T15:03:07.890955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['configs',\n",
       " 'postprocess',\n",
       " 'requirements.txt',\n",
       " '__notebook__.ipynb',\n",
       " 'submission.csv',\n",
       " 'models',\n",
       " 'requirements_sub.txt',\n",
       " 'data']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/kaggle/working/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2587670",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T15:03:07.960830Z",
     "iopub.status.busy": "2023-06-21T15:03:07.960459Z",
     "iopub.status.idle": "2023-06-21T15:03:09.237758Z",
     "shell.execute_reply": "2023-06-21T15:03:09.236125Z"
    },
    "papermill": {
     "duration": 1.301424,
     "end_time": "2023-06-21T15:03:09.240961",
     "exception": false,
     "start_time": "2023-06-21T15:03:07.939537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf /kaggle/working/configs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d95d8d9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T15:03:09.300437Z",
     "iopub.status.busy": "2023-06-21T15:03:09.299413Z",
     "iopub.status.idle": "2023-06-21T15:03:10.727810Z",
     "shell.execute_reply": "2023-06-21T15:03:10.726328Z"
    },
    "papermill": {
     "duration": 1.460274,
     "end_time": "2023-06-21T15:03:10.730626",
     "exception": false,
     "start_time": "2023-06-21T15:03:09.270352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf /kaggle/working/postprocess/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1337efd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T15:03:10.773289Z",
     "iopub.status.busy": "2023-06-21T15:03:10.772893Z",
     "iopub.status.idle": "2023-06-21T15:03:11.921190Z",
     "shell.execute_reply": "2023-06-21T15:03:11.919700Z"
    },
    "papermill": {
     "duration": 1.172436,
     "end_time": "2023-06-21T15:03:11.923983",
     "exception": false,
     "start_time": "2023-06-21T15:03:10.751547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf /kaggle/working/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ab5a3b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T15:03:11.963767Z",
     "iopub.status.busy": "2023-06-21T15:03:11.963404Z",
     "iopub.status.idle": "2023-06-21T15:03:13.175860Z",
     "shell.execute_reply": "2023-06-21T15:03:13.174350Z"
    },
    "papermill": {
     "duration": 1.235811,
     "end_time": "2023-06-21T15:03:13.178614",
     "exception": false,
     "start_time": "2023-06-21T15:03:11.942803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf /kaggle/working/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531503ba",
   "metadata": {
    "papermill": {
     "duration": 0.018619,
     "end_time": "2023-06-21T15:03:13.216323",
     "exception": false,
     "start_time": "2023-06-21T15:03:13.197704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 450.2097,
   "end_time": "2023-06-21T15:03:16.331957",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-21T14:55:46.122257",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00fc55b3229c4f258aa379fdefcb9166": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0225fb0bc07a43ecb2bafb129d50f396": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0497c8fa7243439a9d3f24ee7fbb00dd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "08ad5bed78d14c768219edd7cc3ec82f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0d239aadc81c459b9a2681041e0adc7b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fbe855c2719a450897191e7aa3d6b400",
       "placeholder": "​",
       "style": "IPY_MODEL_bafe3651cc5a431d85eac1bbfb6bc458",
       "value": "100%"
      }
     },
     "12c2c83fbd814bf28c056463b22ed256": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c82f8723892847c5a7e595bdc2aaedaa",
       "placeholder": "​",
       "style": "IPY_MODEL_86041f6e760c426caa13babd667bdbc8",
       "value": "100%"
      }
     },
     "144dbf119640435683885f76543fc07d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1b12dfa80517456aad14865e3b0f9184": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_244437c48864407f8ba4709f94597999",
        "IPY_MODEL_5468871eacca4a088bf89b60e8d5d6f4",
        "IPY_MODEL_479dce63870744d7bee70c7efdcaa60c"
       ],
       "layout": "IPY_MODEL_37d14cabbe564a1994d8b079a651db0a"
      }
     },
     "1ccb51f54b054e3b84d5b191d38b0219": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "20c7afb030f342aa8f0449abc05fea1e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "20d3bacd5d4647d2a90bf14df94efe7b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "244437c48864407f8ba4709f94597999": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_08ad5bed78d14c768219edd7cc3ec82f",
       "placeholder": "​",
       "style": "IPY_MODEL_3b07492d3cc24754b21d05e86535ba1f",
       "value": "100%"
      }
     },
     "2a212cb7eebd475f8a614f33444a3111": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2f5f921842a742668dfca231defad791": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3433da67a369441d9b359ec94188365d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "358656e01cab4e55bebc64b8a7695c21": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3666e897ad4d4123937b43bd913d0ed4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "37d14cabbe564a1994d8b079a651db0a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "37dada29467a45379f6930916c96d9e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0497c8fa7243439a9d3f24ee7fbb00dd",
       "placeholder": "​",
       "style": "IPY_MODEL_50ff8e49bcd14474a02587bbd288fea8",
       "value": "100%"
      }
     },
     "390f8c82bca34b1fa9fce45ece37d664": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3b07492d3cc24754b21d05e86535ba1f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3dde2b2b0cd84158afbf8e4032447f18": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "479dce63870744d7bee70c7efdcaa60c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2f5f921842a742668dfca231defad791",
       "placeholder": "​",
       "style": "IPY_MODEL_999b2bcc94774b54ab6a76989c90d429",
       "value": " 1/1 [00:06&lt;00:00,  5.90s/it]"
      }
     },
     "50ff8e49bcd14474a02587bbd288fea8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "525eb965dddb4274b6e29f98f3a6970f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ebaf0705e86d472195651068f2869767",
       "placeholder": "​",
       "style": "IPY_MODEL_8a11289a1225475da57f5cf2f2611c99",
       "value": " 1/1 [00:08&lt;00:00,  8.55s/it]"
      }
     },
     "5468871eacca4a088bf89b60e8d5d6f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_20d3bacd5d4647d2a90bf14df94efe7b",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_76dcde14158146daaeb7366925aee85b",
       "value": 1.0
      }
     },
     "5b9cc5f8381947d29bfe87c44201266f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_80b1fcaa1e4b4fccb468519cf7cf9ebb",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_df90fa95321e494dae871b6dccbb567b",
       "value": 1.0
      }
     },
     "61b0154f1cd84497977f13697868d04f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3666e897ad4d4123937b43bd913d0ed4",
       "placeholder": "​",
       "style": "IPY_MODEL_7a5348992fa7481ca295f4d85d54ae78",
       "value": " 1/1 [00:05&lt;00:00,  5.91s/it]"
      }
     },
     "66d42c6b7574479f92e8e6445bc832e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a34fc58a46194fcaab83520569efcd07",
        "IPY_MODEL_5b9cc5f8381947d29bfe87c44201266f",
        "IPY_MODEL_525eb965dddb4274b6e29f98f3a6970f"
       ],
       "layout": "IPY_MODEL_c2e5be1d78af48ad8ff958be504222e8"
      }
     },
     "6a4ad9abf6af41bba1da43052f0521ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_144dbf119640435683885f76543fc07d",
       "placeholder": "​",
       "style": "IPY_MODEL_20c7afb030f342aa8f0449abc05fea1e",
       "value": " 1/1 [00:19&lt;00:00, 19.19s/it]"
      }
     },
     "76dcde14158146daaeb7366925aee85b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7820d49794f846029f78d637034a0ca6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0d239aadc81c459b9a2681041e0adc7b",
        "IPY_MODEL_c0f56529418c4afeb9aa047188718dd9",
        "IPY_MODEL_8f8fdbca433347438670b99ebba99b7a"
       ],
       "layout": "IPY_MODEL_1ccb51f54b054e3b84d5b191d38b0219"
      }
     },
     "7a5348992fa7481ca295f4d85d54ae78": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "80b1fcaa1e4b4fccb468519cf7cf9ebb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8191b3ecae744e9a977dd6333ac5f667": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_37dada29467a45379f6930916c96d9e3",
        "IPY_MODEL_9786e372d7354f13b6cec221226e1738",
        "IPY_MODEL_61b0154f1cd84497977f13697868d04f"
       ],
       "layout": "IPY_MODEL_c7a7ad6d114b4fedbed2bb354adfe294"
      }
     },
     "84ec4fc018094a219925a81b9be2834d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "84fcb61c42e74ba0a5da57c269653ca1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "86041f6e760c426caa13babd667bdbc8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8868435d7856445ca0f2efac97d21579": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8a11289a1225475da57f5cf2f2611c99": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8f8fdbca433347438670b99ebba99b7a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0225fb0bc07a43ecb2bafb129d50f396",
       "placeholder": "​",
       "style": "IPY_MODEL_3433da67a369441d9b359ec94188365d",
       "value": " 1/1 [00:20&lt;00:00, 20.63s/it]"
      }
     },
     "9786e372d7354f13b6cec221226e1738": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_00fc55b3229c4f258aa379fdefcb9166",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_84fcb61c42e74ba0a5da57c269653ca1",
       "value": 1.0
      }
     },
     "999b2bcc94774b54ab6a76989c90d429": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9b1a714d43f04650b076b75209569f52": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_12c2c83fbd814bf28c056463b22ed256",
        "IPY_MODEL_e7dc2d6870c94caa84b10c4d0f409f99",
        "IPY_MODEL_6a4ad9abf6af41bba1da43052f0521ca"
       ],
       "layout": "IPY_MODEL_3dde2b2b0cd84158afbf8e4032447f18"
      }
     },
     "a34fc58a46194fcaab83520569efcd07": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_358656e01cab4e55bebc64b8a7695c21",
       "placeholder": "​",
       "style": "IPY_MODEL_84ec4fc018094a219925a81b9be2834d",
       "value": "100%"
      }
     },
     "bafe3651cc5a431d85eac1bbfb6bc458": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c0f56529418c4afeb9aa047188718dd9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_390f8c82bca34b1fa9fce45ece37d664",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c4de8af8eab047498de7fc934d1f27ae",
       "value": 1.0
      }
     },
     "c2e5be1d78af48ad8ff958be504222e8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c4de8af8eab047498de7fc934d1f27ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c7a7ad6d114b4fedbed2bb354adfe294": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c82f8723892847c5a7e595bdc2aaedaa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "df90fa95321e494dae871b6dccbb567b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e7dc2d6870c94caa84b10c4d0f409f99": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8868435d7856445ca0f2efac97d21579",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2a212cb7eebd475f8a614f33444a3111",
       "value": 1.0
      }
     },
     "ebaf0705e86d472195651068f2869767": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fbe855c2719a450897191e7aa3d6b400": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
