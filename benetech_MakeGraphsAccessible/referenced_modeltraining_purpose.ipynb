{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pix2Struct Fine-tuning for Graph data extraction + AMP + W&B logging ðŸš€\n",
    "\n",
    "This notebook (read scratch pad) shows how you can fine-tune Google's Pix2Struct base model for DocVQA (Document Visual Question Answering) on the competition's data.\n",
    "\n",
    "Currently, the loss is quite terrible (reason being I can't adjust the hyperparameters too much without running out of memory) but IT TRAINS. Sticking on little hope there :')\n",
    "\n",
    "If you wish to play with hyperparameters (might cause brain cell loss in certain cases due to OOM), please fork this notebook and be my guest.\n",
    "I really wish to see some of you extend my work and do something cool with this!\n",
    "\n",
    "You can find my current selection of hyperparameters in the `Config` dictionary.\n",
    "\n",
    "Hope you all find this useful!\n",
    "\n",
    "P.S: Huge thanks to [@nbroad's](https://www.kaggle.com/nbroad) donut training [notebook](https://www.kaggle.com/code/nbroad/donut-train-benetech)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://img.shields.io/badge/Upvote-If%20you%20like%20my%20work-07b3c8?style=for-the-badge&logo=kaggle\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-04-11T12:18:46.319997Z",
     "iopub.status.busy": "2023-04-11T12:18:46.318943Z",
     "iopub.status.idle": "2023-04-11T12:19:17.254456Z",
     "shell.execute_reply": "2023-04-11T12:19:17.253111Z",
     "shell.execute_reply.started": "2023-04-11T12:18:46.319958Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-11T12:10:07.428368Z",
     "iopub.status.busy": "2023-04-11T12:10:07.427957Z",
     "iopub.status.idle": "2023-04-11T12:10:19.852929Z",
     "shell.execute_reply": "2023-04-11T12:10:19.851872Z",
     "shell.execute_reply.started": "2023-04-11T12:10:07.428325Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "from transformers import (\n",
    "    AutoProcessor,\n",
    "    Pix2StructConfig,\n",
    "    Pix2StructForConditionalGeneration,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T12:10:19.855523Z",
     "iopub.status.busy": "2023-04-11T12:10:19.85431Z",
     "iopub.status.idle": "2023-04-11T12:10:19.861696Z",
     "shell.execute_reply": "2023-04-11T12:10:19.860705Z",
     "shell.execute_reply.started": "2023-04-11T12:10:19.855469Z"
    }
   },
   "outputs": [],
   "source": [
    "Config = {\n",
    "    'IMAGE_DIR': '/kaggle/input/benetech-making-graphs-accessible/train/images/',\n",
    "    'MAX_PATCHES': 1024,\n",
    "    'MODEL_NAME': 'ybelkada/pix2struct-base',\n",
    "    'IMG_SIZE': (256, 256),\n",
    "    'MAX_LEN': 256,\n",
    "    'LR': 3e-5,\n",
    "    'NB_EPOCHS': 2,\n",
    "    'TRAIN_BS': 2,\n",
    "    'VALID_BS': 2,\n",
    "    'ALL_SAMPLES': int(1e+100),\n",
    "    '_wandb_kernel': 'tanaym',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About W&B:\n",
    "<center><img src=\"https://i.imgur.com/gb6B4ig.png\" width=\"400\" alt=\"Weights & Biases\"/></center><br>\n",
    "<p style=\"text-align:center\">WandB is a developer tool for companies turn deep learning research projects into deployed software by helping teams track their models, visualize model performance and easily automate training and improving models.\n",
    "We will use their tools to log hyperparameters and output metrics from your runs, then visualize and compare results and quickly share findings with your colleagues.<br><br></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To login to W&B, you can use below snippet.\n",
    "\n",
    "```python\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "wb_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    "\n",
    "wandb.login(key=wb_key)\n",
    "```\n",
    "Make sure you have your W&B key stored as `WANDB_API_KEY` under Add-ons -> Secrets\n",
    "\n",
    "You can view [this](https://www.kaggle.com/ayuraj/experiment-tracking-with-weights-and-biases) notebook to learn more about W&B tracking.\n",
    "\n",
    "If you don't want to login to W&B, the kernel will still work and log everything to W&B in anonymous mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T12:10:19.864198Z",
     "iopub.status.busy": "2023-04-11T12:10:19.863448Z",
     "iopub.status.idle": "2023-04-11T12:10:53.301085Z",
     "shell.execute_reply": "2023-04-11T12:10:53.300008Z",
     "shell.execute_reply.started": "2023-04-11T12:10:19.864161Z"
    }
   },
   "outputs": [],
   "source": [
    "def wandb_log(**kwargs):\n",
    "    for k, v in kwargs.items():\n",
    "        wandb.log({k: v})\n",
    "\n",
    "# Start W&B logging\n",
    "# W&B Login\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "wb_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    "\n",
    "wandb.login(key=wb_key)\n",
    "\n",
    "run = wandb.init(\n",
    "    project='pytorch',\n",
    "    config=Config,\n",
    "    group='multi_modal',\n",
    "    job_type='train',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T12:10:53.310783Z",
     "iopub.status.busy": "2023-04-11T12:10:53.308158Z",
     "iopub.status.idle": "2023-04-11T12:10:53.318275Z",
     "shell.execute_reply": "2023-04-11T12:10:53.317181Z",
     "shell.execute_reply.started": "2023-04-11T12:10:53.310742Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's add chart types as special tokens and a special BOS token\n",
    "BOS_TOKEN = \"<|BOS|>\"\n",
    "X_START = \"<x_start>\"\n",
    "X_END = \"<x_end>\"\n",
    "Y_START = \"<y_start>\"\n",
    "Y_END = \"<y_end>\"\n",
    "\n",
    "new_tokens = [\n",
    "    \"<line>\",\n",
    "    \"<vertical_bar>\",\n",
    "    \"<scatter>\",\n",
    "    \"<dot>\",\n",
    "    \"<horizontal_bar>\",\n",
    "    X_START,\n",
    "    X_END,\n",
    "    Y_START,\n",
    "    Y_END,\n",
    "    BOS_TOKEN,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just resizing and graph image normalization as augments for now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T12:10:53.326428Z",
     "iopub.status.busy": "2023-04-11T12:10:53.3238Z",
     "iopub.status.idle": "2023-04-11T12:10:53.335427Z",
     "shell.execute_reply": "2023-04-11T12:10:53.334425Z",
     "shell.execute_reply.started": "2023-04-11T12:10:53.326387Z"
    }
   },
   "outputs": [],
   "source": [
    "def augments():\n",
    "    return A.Compose([\n",
    "        A.Resize(width=Config['IMG_SIZE'][0], height=Config['IMG_SIZE'][1]),\n",
    "        A.Normalize(\n",
    "            mean=[0, 0, 0],\n",
    "            std=[1, 1, 1],\n",
    "            max_pixel_value=255,\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T12:10:53.34419Z",
     "iopub.status.busy": "2023-04-11T12:10:53.341048Z",
     "iopub.status.idle": "2023-04-11T12:10:53.356034Z",
     "shell.execute_reply": "2023-04-11T12:10:53.354959Z",
     "shell.execute_reply.started": "2023-04-11T12:10:53.344149Z"
    }
   },
   "outputs": [],
   "source": [
    "class BeneTechDataset(Dataset):\n",
    "    def __init__(self, dataset, processor, augments=None):\n",
    "        self.dataset = dataset\n",
    "        self.processor = processor\n",
    "        self.augments = augments\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        image = cv2.imread(item['image'])\n",
    "        if self.augments:\n",
    "            image = self.augments(image=image)['image']\n",
    "        encoding = self.processor(\n",
    "            images=image,\n",
    "            return_tensors=\"pt\", \n",
    "            add_special_tokens=True, \n",
    "            max_patches=Config['MAX_PATCHES']\n",
    "        )\n",
    "        \n",
    "        encoding = {k:v.squeeze() for k,v in encoding.items()}\n",
    "        encoding[\"text\"] = item[\"label\"]\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you make changes to the vocab or anything else in the below cell, please don't forget to resize model token embeddings (as done below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T12:10:53.363904Z",
     "iopub.status.busy": "2023-04-11T12:10:53.361124Z",
     "iopub.status.idle": "2023-04-11T12:10:53.373469Z",
     "shell.execute_reply": "2023-04-11T12:10:53.37227Z",
     "shell.execute_reply.started": "2023-04-11T12:10:53.363865Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(extra_tokens=new_tokens):\n",
    "    processor = AutoProcessor.from_pretrained(Config['MODEL_NAME'])\n",
    "    model = Pix2StructForConditionalGeneration.from_pretrained(Config['MODEL_NAME'])\n",
    "    processor.image_processor.size = {\n",
    "        \"height\": Config['IMG_SIZE'][0],\n",
    "        \"width\": Config['IMG_SIZE'][1],\n",
    "    }\n",
    "\n",
    "    processor.tokenizer.add_tokens(extra_tokens)\n",
    "    model.resize_token_embeddings(len(processor.tokenizer))\n",
    "    return processor, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T12:10:53.382874Z",
     "iopub.status.busy": "2023-04-11T12:10:53.379996Z",
     "iopub.status.idle": "2023-04-11T12:10:53.394607Z",
     "shell.execute_reply": "2023-04-11T12:10:53.39338Z",
     "shell.execute_reply.started": "2023-04-11T12:10:53.382828Z"
    }
   },
   "outputs": [],
   "source": [
    "def collator(batch):\n",
    "    new_batch = {\"flattened_patches\":[], \"attention_mask\":[]}\n",
    "    texts = [item[\"text\"] for item in batch]\n",
    "    text_inputs = processor(\n",
    "        text=texts, \n",
    "        padding=\"max_length\", \n",
    "        truncation=True, \n",
    "        return_tensors=\"pt\", \n",
    "        add_special_tokens=True, \n",
    "        max_length=Config['MAX_LEN']\n",
    "    )\n",
    "    new_batch[\"labels\"] = text_inputs.input_ids\n",
    "    for item in batch:\n",
    "        new_batch[\"flattened_patches\"].append(item[\"flattened_patches\"])\n",
    "        new_batch[\"attention_mask\"].append(item[\"attention_mask\"])\n",
    "    new_batch[\"flattened_patches\"] = torch.stack(new_batch[\"flattened_patches\"])\n",
    "    new_batch[\"attention_mask\"] = torch.stack(new_batch[\"attention_mask\"])\n",
    "\n",
    "    return new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T12:10:53.40313Z",
     "iopub.status.busy": "2023-04-11T12:10:53.400154Z",
     "iopub.status.idle": "2023-04-11T12:10:53.421967Z",
     "shell.execute_reply": "2023-04-11T12:10:53.420579Z",
     "shell.execute_reply.started": "2023-04-11T12:10:53.403091Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, processor, train_loader, optimizer, scaler):\n",
    "    \"\"\"\n",
    "    Trains the model on all batches for one epoch with NVIDIA's AMP\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    avg_loss = 0\n",
    "    with autocast():\n",
    "        prog_bar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "        for idx, batch in prog_bar:\n",
    "            labels = batch.pop(\"labels\").to('cuda')\n",
    "            flattened_patches = batch.pop(\"flattened_patches\").to('cuda')\n",
    "            attention_mask = batch.pop(\"attention_mask\").to('cuda')\n",
    "\n",
    "            outputs = model(\n",
    "                flattened_patches=flattened_patches,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            prog_bar.set_description(f\"loss: {loss.item():.4f}\")\n",
    "            wandb_log(train_step_loss=loss.item())\n",
    "            avg_loss += loss.item()\n",
    "            \n",
    "    avg_loss = avg_loss / len(train_loader)\n",
    "    print(f\"Average training loss: {avg_loss:.4f}\")\n",
    "    wandb_log(train_loss=avg_loss)\n",
    "    return avg_loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, processor, valid_loader):\n",
    "    \"\"\"\n",
    "    Validates the model on all batches (in val set) for one epoch\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    avg_loss = 0\n",
    "    prog_bar = tqdm(enumerate(valid_loader), total=len(valid_loader))\n",
    "    for idx, batch in prog_bar:\n",
    "        labels = batch.pop(\"labels\").to('cuda')\n",
    "        flattened_patches = batch.pop(\"flattened_patches\").to('cuda')\n",
    "        attention_mask = batch.pop(\"attention_mask\").to('cuda')\n",
    "        \n",
    "        outputs = model(\n",
    "            flattened_patches=flattened_patches,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        prog_bar.set_description(f\"loss: {loss.item():.4f}\")\n",
    "        wandb_log(val_step_loss=loss.item())\n",
    "        avg_loss += loss.item()\n",
    "        \n",
    "    avg_loss = avg_loss / len(valid_loader)\n",
    "    print(f\"Average validation loss: {avg_loss:.4f}\")\n",
    "    wandb_log(val_loss=avg_loss)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T12:10:53.431027Z",
     "iopub.status.busy": "2023-04-11T12:10:53.428182Z",
     "iopub.status.idle": "2023-04-11T12:10:53.440957Z",
     "shell.execute_reply": "2023-04-11T12:10:53.439969Z",
     "shell.execute_reply.started": "2023-04-11T12:10:53.430987Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit(model, processor, train_loader, valid_loader, optimizer, scaler):\n",
    "    \"\"\"\n",
    "    A nice function that binds it all together and reminds me of Keras days from 2018 :)\n",
    "    \"\"\"\n",
    "    best_val_loss = int(1e+5)\n",
    "    for epoch in range(Config['NB_EPOCHS']):\n",
    "        print(f\"{'='*20} Epoch: {epoch+1} / {Config['NB_EPOCHS']} {'='*20}\")\n",
    "        _ = train_one_epoch(model, processor, train_loader, optimizer, scaler)\n",
    "        val_avg_loss = valid_one_epoch(model, processor, valid_loader)\n",
    "        \n",
    "        if val_avg_loss < best_val_loss:\n",
    "            best_val_loss = val_avg_loss\n",
    "            print(f\"Saving best model so far with loss: {best_val_loss:.4f}\")\n",
    "            torch.save(model.state_dict(), f\"pix2struct_base_benetech.pt\")\n",
    "    print(f\"Best model with val_loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T12:10:53.449365Z",
     "iopub.status.busy": "2023-04-11T12:10:53.446614Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training cell\n",
    "if __name__ == \"__main__\":\n",
    "    # Read the processed JSON file\n",
    "    with open(\"/kaggle/input/benetech-processed-data-json/data.json\", \"r\") as fl:\n",
    "        dataset = json.load(fl)['data']\n",
    "        \n",
    "    # Shuffle the dataset and select however samples you want for training\n",
    "    shuffle(dataset)\n",
    "    dataset = dataset[:Config['ALL_SAMPLES']]\n",
    "    \n",
    "    # We are splitting the data naively for now\n",
    "    split = 0.90\n",
    "    train_samples = int(len(dataset) * split)\n",
    "    train_ds = dataset[:train_samples+1]\n",
    "    valid_ds = dataset[train_samples:]\n",
    "    \n",
    "    # Yeah all that\n",
    "    processor, model = get_model()\n",
    "    model.to('cuda')\n",
    "    wandb.watch(model)\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=Config['LR'])\n",
    "    \n",
    "    # Load the data into Datasets and then make DataLoaders for training\n",
    "    train_dataset = BeneTechDataset(train_ds, processor, augments=augments())\n",
    "    train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=Config['TRAIN_BS'], collate_fn=collator)\n",
    "    \n",
    "    valid_dataset = BeneTechDataset(valid_ds, processor, augments=augments())\n",
    "    valid_dataloader = DataLoader(valid_dataset, shuffle=False, batch_size=Config['VALID_BS'], collate_fn=collator)\n",
    "    \n",
    "    nb_train_steps = int(train_samples / Config['TRAIN_BS'] * Config['NB_EPOCHS'])\n",
    "    \n",
    "    # Print out the data sizes we are training on\n",
    "    print(f\"Training on {len(train_ds)} samples, Validating on {len(valid_ds)} samples\")\n",
    "    \n",
    "    # Train the model now\n",
    "    fit(\n",
    "        model=model,\n",
    "        processor=processor,\n",
    "        train_loader=train_dataloader,\n",
    "        valid_loader=valid_dataloader,\n",
    "        optimizer=optimizer,\n",
    "        scaler=GradScaler(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once training is done, \n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://img.shields.io/badge/Upvote-If%20you%20like%20my%20work-07b3c8?style=for-the-badge&logo=kaggle\">\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
