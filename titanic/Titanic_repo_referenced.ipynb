{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "e12020f7-4f94-4ecc-9007-9b7a6e7458a6",
    "_uuid": "1fecb0980d8d422ec0f005c4bfd6225385c2c60f",
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NumPy\n",
    "import numpy as np\n",
    "\n",
    "# Dataframe operations\n",
    "import pandas as pd\n",
    "\n",
    "# Data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scalers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression #logistic regression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn import svm #support vector Machine\n",
    "from sklearn.ensemble import RandomForestClassifier #Random Forest\n",
    "from sklearn.neighbors import KNeighborsClassifier #KNN\n",
    "from sklearn.naive_bayes import GaussianNB #Naive bayes\n",
    "from sklearn.tree import DecisionTreeClassifier #Decision Tree\n",
    "from sklearn.model_selection import train_test_split #training and testing data split\n",
    "from sklearn import metrics #accuracy measure\n",
    "from sklearn.metrics import confusion_matrix #for confusion matrix\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Cross-validation\n",
    "from sklearn.model_selection import KFold #for K-fold cross validation\n",
    "from sklearn.model_selection import cross_val_score #score evaluation\n",
    "from sklearn.model_selection import cross_val_predict #prediction\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Common Model Algorithms\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "\n",
    "#Common Model Helpers\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "#Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d49e43e8-0dc0-41b7-afd0-60acc96e9f07",
    "_uuid": "4ecd55c5bd48390d026eeb6ae8de0a7ace0d4ada"
   },
   "source": [
    "## Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "9c963eb3-04ac-422c-bc0c-4373bda6880e",
    "_uuid": "95f406c4d2f1dab6744ea248b80e3a535c652450",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kendt\\AppData\\Local\\Temp\\ipykernel_27188\\101556385.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_df = train_df.append(test_df) # The entire data: train + test.\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "data_df = train_df.append(test_df) # The entire data: train + test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "687a06ef-2686-4772-ac24-5e413adbda6d",
    "_uuid": "3846eff13d723fa6ff10117fc3ebc46f266b210f"
   },
   "source": [
    "# Engineering features\n",
    "\n",
    " - **Imputing Age**\n",
    " \n",
    "I make a Title feature for imputing ages more precisely. Median is used because ages distribution is not always normal, so it's generally preferred over mean. But I don't think this matters a lot, you can use mean too.\n",
    "I don't use Title feature for fitting models so it's discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "46535259-a34c-4305-b19e-b6772834c2b1",
    "_uuid": "811b1c66a647266d203e54175918a2c906e98ee5",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data_df['Title'] = data_df['Name']\n",
    "# Cleaning name and extracting Title\n",
    "for name_string in data_df['Name']:\n",
    "    data_df['Title'] = data_df['Name'].str.extract('([A-Za-z]+)\\.', expand=True)\n",
    "\n",
    "# Replacing rare titles with more common ones\n",
    "mapping = {'Mlle': 'Miss', 'Major': 'Mr', 'Col': 'Mr', 'Sir': 'Mr', 'Don': 'Mr', 'Mme': 'Miss',\n",
    "          'Jonkheer': 'Mr', 'Lady': 'Mrs', 'Capt': 'Mr', 'Countess': 'Mrs', 'Ms': 'Miss', 'Dona': 'Mrs'}\n",
    "data_df.replace({'Title': mapping}, inplace=True)\n",
    "titles = ['Dr', 'Master', 'Miss', 'Mr', 'Mrs', 'Rev']\n",
    "for title in titles:\n",
    "    age_to_impute = data_df.groupby('Title')['Age'].median()[titles.index(title)]\n",
    "    data_df.loc[(data_df['Age'].isnull()) & (data_df['Title'] == title), 'Age'] = age_to_impute\n",
    "    \n",
    "# Substituting Age values in TRAIN_DF and TEST_DF:\n",
    "train_df['Age'] = data_df['Age'][:891]\n",
    "test_df['Age'] = data_df['Age'][891:]\n",
    "\n",
    "# Dropping Title feature\n",
    "data_df.drop('Title', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4c6142e2-e351-4063-81a6-4836b4ab1b18",
    "_uuid": "ee4ddbb2ef693943bb766083c4bfc1ef4f173103"
   },
   "source": [
    " - **Adding Family_Size**\n",
    " \n",
    "That's just Parch + SibSp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "c181cefb-edd6-4d46-95c8-67b89d83ca1c",
    "_uuid": "d562760d23fa303cb93069f339bbab01fcd96486",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data_df['Family_Size'] = data_df['Parch'] + data_df['SibSp']\n",
    "\n",
    "# Substituting Age values in TRAIN_DF and TEST_DF:\n",
    "train_df['Family_Size'] = data_df['Family_Size'][:891]\n",
    "test_df['Family_Size'] = data_df['Family_Size'][891:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "463912c1-1f64-4fb4-9196-969f29dbbd8a",
    "_uuid": "984ac1ddd587b2aec9d520f3281c3d52208de7e8"
   },
   "source": [
    " - **Adding Family_Survival**\n",
    " \n",
    " This feature is from [S.Xu's kernel](https://www.kaggle.com/shunjiangxu/blood-is-thicker-than-water-friendship-forever), he groups families and people with the same tickets togerher and researches the info. I've cleaned the code a bit but it still does the same, I left it as is. For comments see the original kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "5939ba63-cead-4af6-86b9-587f433d63ec",
    "_uuid": "d01422f5894c381d88e036808a5aa1ba9f48b00d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of passengers with family survival information: 420\n"
     ]
    }
   ],
   "source": [
    "data_df['Last_Name'] = data_df['Name'].apply(lambda x: str.split(x, \",\")[0])\n",
    "data_df['Fare'].fillna(data_df['Fare'].mean(), inplace=True)\n",
    "\n",
    "DEFAULT_SURVIVAL_VALUE = 0.5\n",
    "data_df['Family_Survival'] = DEFAULT_SURVIVAL_VALUE\n",
    "\n",
    "for grp, grp_df in data_df[['Survived','Name', 'Last_Name', 'Fare', 'Ticket', 'PassengerId',\n",
    "                           'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['Last_Name', 'Fare']):\n",
    "    \n",
    "    if (len(grp_df) != 1):\n",
    "        # A Family group is found.\n",
    "        for ind, row in grp_df.iterrows():\n",
    "            smax = grp_df.drop(ind)['Survived'].max()\n",
    "            smin = grp_df.drop(ind)['Survived'].min()\n",
    "            passID = row['PassengerId']\n",
    "            if (smax == 1.0):\n",
    "                data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 1\n",
    "            elif (smin==0.0):\n",
    "                data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 0\n",
    "\n",
    "print(\"Number of passengers with family survival information:\", \n",
    "      data_df.loc[data_df['Family_Survival']!=0.5].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "8f31cc67-1425-4e2b-8a29-4fa97b87dcdc",
    "_uuid": "3e19ae6012724aa5f8cee2b1b69af975ad42ac4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of passenger with family/group survival information: 546\n"
     ]
    }
   ],
   "source": [
    "for _, grp_df in data_df.groupby('Ticket'):\n",
    "    if (len(grp_df) != 1):\n",
    "        for ind, row in grp_df.iterrows():\n",
    "            if (row['Family_Survival'] == 0) | (row['Family_Survival']== 0.5):\n",
    "                smax = grp_df.drop(ind)['Survived'].max()\n",
    "                smin = grp_df.drop(ind)['Survived'].min()\n",
    "                passID = row['PassengerId']\n",
    "                if (smax == 1.0):\n",
    "                    data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 1\n",
    "                elif (smin==0.0):\n",
    "                    data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 0\n",
    "                        \n",
    "print(\"Number of passenger with family/group survival information: \" \n",
    "      +str(data_df[data_df['Family_Survival']!=0.5].shape[0]))\n",
    "\n",
    "# # Family_Survival in TRAIN_DF and TEST_DF:\n",
    "train_df['Family_Survival'] = data_df['Family_Survival'][:891]\n",
    "test_df['Family_Survival'] = data_df['Family_Survival'][891:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8f5064af-21a0-4172-9565-24345d232db8",
    "_uuid": "b903a6f5c2bcfb587a722c4903c84389cae1b163"
   },
   "source": [
    " - **Making FARE BINS**\n",
    " \n",
    "It's ordinal. FareBin = 3 is indeed greater than FareBin = 1. I've seen people turning it into dummies for some reason..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "084602ad-6739-441a-a153-23ed0de0a2df",
    "_uuid": "87e965a43b010f8589d3559c13829c5f8a7445d0",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kendt\\AppData\\Local\\Temp\\ipykernel_27188\\3764749092.py:12: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  train_df.drop(['Fare'], 1, inplace=True)\n",
      "C:\\Users\\kendt\\AppData\\Local\\Temp\\ipykernel_27188\\3764749092.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  test_df.drop(['Fare'], 1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data_df['Fare'].fillna(data_df['Fare'].median(), inplace = True)\n",
    "\n",
    "# Making Bins\n",
    "data_df['FareBin'] = pd.qcut(data_df['Fare'], 5)\n",
    "\n",
    "label = LabelEncoder()\n",
    "data_df['FareBin_Code'] = label.fit_transform(data_df['FareBin'])\n",
    "\n",
    "train_df['FareBin_Code'] = data_df['FareBin_Code'][:891]\n",
    "test_df['FareBin_Code'] = data_df['FareBin_Code'][891:]\n",
    "\n",
    "train_df.drop(['Fare'], 1, inplace=True)\n",
    "test_df.drop(['Fare'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9ed9de97-5f49-48c4-91a5-a2fdd019ee7a",
    "_uuid": "94052ac922229ec3b1bd7d29ead82c2bea76e2b5"
   },
   "source": [
    " - **Making AGE BINS**\n",
    " \n",
    "Note here that it is better to use the entire dataset for mean/median/mode calculation, otherwise we will miss out useful information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "2c8f80c6-d271-4716-87b6-9dc31ee5f967",
    "_uuid": "8fb78bde0f082a32e9abfb21c52c67bb4d05ae3e",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kendt\\AppData\\Local\\Temp\\ipykernel_27188\\11583694.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  train_df.drop(['Age'], 1, inplace=True)\n",
      "C:\\Users\\kendt\\AppData\\Local\\Temp\\ipykernel_27188\\11583694.py:10: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  test_df.drop(['Age'], 1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data_df['AgeBin'] = pd.qcut(data_df['Age'], 4)\n",
    "\n",
    "label = LabelEncoder()\n",
    "data_df['AgeBin_Code'] = label.fit_transform(data_df['AgeBin'])\n",
    "\n",
    "train_df['AgeBin_Code'] = data_df['AgeBin_Code'][:891]\n",
    "test_df['AgeBin_Code'] = data_df['AgeBin_Code'][891:]\n",
    "\n",
    "train_df.drop(['Age'], 1, inplace=True)\n",
    "test_df.drop(['Age'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ef2fd090-e439-4bc0-8e96-1615ccda6f22",
    "_uuid": "8d3893970c76f066263d155207236d666e8259a8"
   },
   "source": [
    " - **Mapping SEX and cleaning data (dropping garbage) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "b5c6cdd4-3211-4032-b9e3-7a4e4dd49858",
    "_uuid": "33361df2ab42f24ba31471d2dd8b8bd49f1f1151",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_df['Sex'].replace(['male','female'],[0,1],inplace=True)\n",
    "test_df['Sex'].replace(['male','female'],[0,1],inplace=True)\n",
    "\n",
    "train_df.drop(['Name', 'PassengerId', 'SibSp', 'Parch', 'Ticket', 'Cabin',\n",
    "               'Embarked'], axis = 1, inplace = True)\n",
    "test_df.drop(['Name','PassengerId', 'SibSp', 'Parch', 'Ticket', 'Cabin',\n",
    "              'Embarked'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "db928505-e1cf-48d0-bf35-b72a7782a774",
    "_uuid": "26631d4c02767d6f54376f07cf35b20dc1f94a58"
   },
   "source": [
    "So now our datasets look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "e33d6e9e-4eb4-4704-81f4-4d536d5dbf53",
    "_uuid": "d32ce4fc0d662432cc733915dd5f1143375f128b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Family_Survival</th>\n",
       "      <th>FareBin_Code</th>\n",
       "      <th>AgeBin_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex  Family_Size  Family_Survival  FareBin_Code  \\\n",
       "0         0       3    0            1              0.5             0   \n",
       "1         1       1    1            1              0.5             4   \n",
       "2         1       3    1            0              0.5             1   \n",
       "\n",
       "   AgeBin_Code  \n",
       "0            0  \n",
       "1            3  \n",
       "2            1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5b91437e-845e-4e3f-a20e-19db3d7a8540",
    "_uuid": "52d1886521f05ac5043ef734d94aadf59cc7a073"
   },
   "source": [
    "# Training\n",
    "\n",
    " - **Creating X and y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "2fdafbf3-62cc-4365-8168-7e149f8b51f0",
    "_uuid": "94e2b9da92605974f2e7575f85b10abf98a0d6b4",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kendt\\AppData\\Local\\Temp\\ipykernel_27188\\246681801.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  X = train_df.drop('Survived', 1)\n"
     ]
    }
   ],
   "source": [
    "X = train_df.drop('Survived', 1)\n",
    "y = train_df['Survived']\n",
    "X_test = test_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "84ece816-177c-473e-92ae-620c5fe50be6",
    "_uuid": "fd73849d6b1805fa835b1031a1e2e812e0ef68e3"
   },
   "source": [
    " - **Scaling features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "6f077d59-c48d-41b2-82b2-7cd325ed4aab",
    "_uuid": "fc95cee7c61fee94005453e2b97598f69267ca29",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "X = std_scaler.fit_transform(X)\n",
    "X_test = std_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bd37c2af-8981-43b0-8a60-da278d130073",
    "_uuid": "e59cb01ea58d9aaf401655bee18c682976956f00"
   },
   "source": [
    " - **Grid Search CV**\n",
    " \n",
    " Here I use KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_cell_guid": "0baa26fd-c625-44a0-9411-b2479ace87ab",
    "_uuid": "670108e53958cb3378a2d7f35043c698cedb05be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 240 candidates, totalling 2400 fits\n",
      "0.8783650227767875\n",
      "KNeighborsClassifier(leaf_size=26, n_neighbors=16)\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = [6,7,8,9,10,11,12,14,16,18,20,22]\n",
    "algorithm = ['auto']\n",
    "weights = ['uniform', 'distance']\n",
    "leaf_size = list(range(1,50,5))\n",
    "hyperparams = {'algorithm': algorithm, 'weights': weights, 'leaf_size': leaf_size, \n",
    "               'n_neighbors': n_neighbors}\n",
    "gd=GridSearchCV(estimator = KNeighborsClassifier(), param_grid = hyperparams, verbose=True, \n",
    "                cv=10, scoring = \"roc_auc\")\n",
    "gd.fit(X, y)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f53279aa-05a3-4f61-b3c6-d54ccc9e3cf9",
    "_uuid": "b8132e9ed17b247ea14e9e0f8235d4806d411cf8"
   },
   "source": [
    "\n",
    "\n",
    "In case you get a different result here (result may vary), what I got was:\n",
    "\n",
    "> KNeighborsClassifier(algorithm='auto', leaf_size=26, metric='minkowski', metric_params=None, n_jobs=1, n_neighbors=18, p=2, weights='uniform')\n",
    "\n",
    "This gave 0.884103388207 ROC_AUC score (not accuracy score!). I had a ton of models with roc_auc around 0.93-0.94 but when tested, they mostly showed lower results. Doesn't mean they are worse though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b91368fc-7671-497c-bea2-bba3b857633c",
    "_uuid": "f2170452b8a8f2fa89f4b5e9bb221e488bf42282"
   },
   "source": [
    " - **Using a model found by grid searching**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_cell_guid": "2ab86ce3-6bc2-46d1-9324-cf496bb1ea06",
    "_uuid": "485df2df733917a8bbf405a9a9eabf792ecb89e4",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "gd.best_estimator_.fit(X, y)\n",
    "y_pred = gd.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f6885421-d2e5-4f06-8d11-f5f4b686b251",
    "_uuid": "a64495aed8957867c0e460880fab6339c9ce981f"
   },
   "source": [
    "When I submitted the result, the model I've specified above yielded [0.82775] public score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "118adb4d-6964-43c3-b971-ecd662b159cb",
    "_uuid": "9cd8d5e04ddc8b1bbbdd0bcb947f53574fee2fc7"
   },
   "source": [
    "- **Using another K**\n",
    "\n",
    "This guy comes from empirical messing around with amount of neighbors in KNN. It's the same as the above one, but with another n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "8adcbc6a-39e7-4fcc-a65d-c9bdd7076c49",
    "_uuid": "9bc6cdd37489b2236275c455b065f3abaed97a17",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(algorithm='auto', leaf_size=26, metric='minkowski', \n",
    "                           metric_params=None, n_jobs=1, n_neighbors=6, p=2, \n",
    "                           weights='uniform')\n",
    "knn.fit(X, y)\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bbb2d758-6854-445f-b290-0e1d0d50da98",
    "_uuid": "617771e6b279a4d1112d27fbc5cc1775d44f3d81"
   },
   "source": [
    "Being a fan of simple models there's no way I couldn't try playing with n_neighbors lowering it (the lower it is --> the less complex the model is, though too simple model is bad news too)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a37e176c-3b55-43ab-b358-324dc384ceef",
    "_uuid": "d4d6df3e6c40063309ea72f4d4cea51cf616fd80"
   },
   "source": [
    "- **Making submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_cell_guid": "8111500e-330c-411e-a742-66b9d4c5cb2c",
    "_uuid": "40858051e4f458835f937275be4dfe3dfa68b25f",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(pd.read_csv(\"test.csv\")['PassengerId'])\n",
    "temp['Survived'] = y_pred\n",
    "temp.to_csv(\"submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "081225b5-2e95-455d-9c2c-2a4b087c156c",
    "_uuid": "dcccce817c650e7830de41704a95484c2a7b0761"
   },
   "source": [
    " ## Result\n",
    "Score is 0.81578 when submitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
